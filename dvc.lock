schema: '2.0'
stages:
  download-images:
    cmd: python scripts/download-images.py datasets/watch-faces.json --concurrent
    deps:
    - path: datasets/watch-faces.json
      md5: 90e20e9d7b05996a1d315efc0d932dad
      size: 1168571
    - path: scripts/download-images.py
      md5: a037cfab1a482a356f1d7d62804041d3
      size: 3961
    outs:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c4fa34aee6031fa6a9da2d86bdb12928.dir
      size: 101323130
      nfiles: 221
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: ff7da7da2e73b2777c9b3d610cab10ff
      size: 1161602
  train-detector:
    cmd: python watch_recognition/watch_recognition/train/object_detection_task.py  --epochs
      100  --batch-size 16  --seed 42
    deps:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c4fa34aee6031fa6a9da2d86bdb12928.dir
      size: 101323130
      nfiles: 221
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: ff7da7da2e73b2777c9b3d610cab10ff
      size: 1161602
    - path: watch_recognition/watch_recognition/train/object_detection_task.py
      md5: e5b158e1ba9fa33d33a5555c4dbb2785
      size: 11006
    params:
      params.yaml:
        detector:
          epochs: 100
          batch-size: 16
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: debug/detector/
      md5: f1db36dfa7d13dcfef466237c7f11444.dir
      size: 933292
      nfiles: 4
    - path: example_predictions/detector/test-image.jpg
      md5: 1f80f19cb2ac1c6be1c1d6978007b769
      size: 129792
    - path: metrics/detector.json
      md5: d45243631d1bd9bc17728cc14ab634e1
      size: 474
    - path: metrics/detector/scalars
      md5: a594c76f503bc69e0f5697390d93a365.dir
      size: 34057
      nfiles: 10
    - path: models/detector/
      md5: ac45f8f7bf58e101223826ad8cac9329.dir
      size: 432253678
      nfiles: 5
  eval-detector:
    cmd: python watch_recognition/watch_recognition/eval/object_detection_eval.py
    deps:
    - path: models/detector/
      md5: ac45f8f7bf58e101223826ad8cac9329.dir
      size: 432253678
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/object_detection_eval.py
      md5: 30402100c451819d2f486ffd6fd5d479
      size: 4929
    outs:
    - path: example_predictions/detector/train_0.jpg
      md5: 016ad43e4fa93b98c31cb6d12ceec0a6
      size: 59982
    - path: example_predictions/detector/train_1.jpg
      md5: ee5316b2703b4fbc3261c04c8efad519
      size: 58168
    - path: example_predictions/detector/train_2.jpg
      md5: 36a1d3943948c58b15c6cdfd7cc43357
      size: 51305
    - path: example_predictions/detector/train_3.jpg
      md5: 0fa46aa121fe808409430681deb0c184
      size: 38705
    - path: example_predictions/detector/val_0.jpg
      md5: c4da402a23c6ff01d33666b8a944b07e
      size: 24591
    - path: example_predictions/detector/val_1.jpg
      md5: 79b881fe8adc8bb5eb3940553addf90e
      size: 57275
    - path: example_predictions/detector/val_2.jpg
      md5: d526d339df2731de322a7e3c344720f5
      size: 41520
    - path: metrics/detector/PR-IoU@0.50_train.tsv
      md5: 73fd20c198ef4b19158b46fa295df506
      size: 2386
    - path: metrics/detector/PR-IoU@0.50_val.tsv
      md5: 721accd77832b511c9d448ab5bbdb54d
      size: 2094
    - path: metrics/detector/PR-IoU@0.75_train.tsv
      md5: 73fd20c198ef4b19158b46fa295df506
      size: 2386
    - path: metrics/detector/PR-IoU@0.75_val.tsv
      md5: 8ed085102d8cfde0081676db2e269f83
      size: 1646
    - path: metrics/detector/PR-IoU@0.95_train.tsv
      md5: 1171c61e40651ff3b4e8328359ae6375
      size: 1453
    - path: metrics/detector/PR-IoU@0.95_val.tsv
      md5: 6010742813bf9bf4da5fb175d964af31
      size: 1127
    - path: metrics/detector/coco_train.json
      md5: 5356f5fa4ccac78a86a66dd9e8059278
      size: 286
    - path: metrics/detector/coco_val.json
      md5: 0f90d5f6ba56073c21d9ce179c1537b5
      size: 285
  update-metrics:
    cmd: python scripts/update-metrics-table-and-graph.py
    deps:
    - path: metrics
      md5: 60061d15e562037a1eb0f68abd048aa4.dir
      size: 450726
      nfiles: 43
    - path: scripts/update-metrics-table-and-graph.py
      md5: b6166e699fc2111731ce9ebed407e806
      size: 2108
  train-keypoint:
    cmd: python watch_recognition/watch_recognition/train/heatmap_regression_task.py
      --epochs 100 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c4fa34aee6031fa6a9da2d86bdb12928.dir
      size: 101323130
      nfiles: 221
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: ff7da7da2e73b2777c9b3d610cab10ff
      size: 1161602
    - path: watch_recognition/watch_recognition/train/heatmap_regression_task.py
      md5: e207cb8a105dddf9c60f93b25e87c4a5
      size: 6826
    params:
      params.yaml:
        keypoint:
          epochs: 100
          batch-size: 32
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: example_predictions/keypoint/test-image-2.jpg
      md5: 7727cfb4fb3ba558506c5827b2eea117
      size: 66363
    - path: metrics/keypoint.json
      md5: 261b7075efcd413d7c458497831388c7
      size: 215
    - path: metrics/keypoint/scalars/
      md5: 07ef9103b4f2a330ed5fa476a6f672fc.dir
      size: 14969
      nfiles: 4
    - path: models/keypoint/
      md5: 4883aa0423b570a75c987fe12917892e.dir
      size: 35988675
      nfiles: 6
  eval-keypoint:
    cmd: python watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      --kp-confidence-threshold 0.5
    deps:
    - path: models/detector/
      md5: ac45f8f7bf58e101223826ad8cac9329.dir
      size: 432253678
      nfiles: 5
    - path: models/keypoint/
      md5: 4883aa0423b570a75c987fe12917892e.dir
      size: 35988675
      nfiles: 6
    - path: watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      md5: 7aee96c16f50bc522e62bc9138f49247
      size: 6302
    outs:
    - path: example_predictions/keypoint/train_0.jpg
      md5: 338a6543b682e3506589062e1342404c
      size: 55602
    - path: example_predictions/keypoint/train_1.jpg
      md5: 842e748f76b5ff23415fa9fd0664f2bf
      size: 52191
    - path: example_predictions/keypoint/train_2.jpg
      md5: 0d4fc0c08f160074264ee1869fc9a9aa
      size: 56068
    - path: example_predictions/keypoint/train_3.jpg
      md5: c988e4ba83ea98b809f21a7fdb868473
      size: 46217
    - path: example_predictions/keypoint/train_4.jpg
      md5: b9129eeb65ef3d923509c1ff463eb6ff
      size: 39486
    - path: example_predictions/keypoint/val_0.jpg
      md5: 6d6cc87f468e2a6ccf8fc3ec4f630aad
      size: 53135
    - path: example_predictions/keypoint/val_1.jpg
      md5: e162d19c6494163cc3a137e9cbd576ed
      size: 60615
    - path: example_predictions/keypoint/val_2.jpg
      md5: c887e63c9b4a3c1f8943840a92f07f2f
      size: 47908
    - path: example_predictions/keypoint/val_3.jpg
      md5: 1e3f059d2b636fb0ab226ec9366193fd
      size: 57323
    - path: example_predictions/keypoint/val_4.jpg
      md5: b7dc1367aae7236c08fc6fa96b3140a8
      size: 50682
    - path: metrics/keypoint/coco_train.json
      md5: 83b0575b2780727222fc8cf43110284a
      size: 262
    - path: metrics/keypoint/coco_val.json
      md5: 9f4a0e0d3dac511d43a053dc179650bc
      size: 260
  train-segmentation:
    cmd: python watch_recognition/watch_recognition/train/segmentation_task.py --epochs
      100 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: c4fa34aee6031fa6a9da2d86bdb12928.dir
      size: 101323130
      nfiles: 221
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: ff7da7da2e73b2777c9b3d610cab10ff
      size: 1161602
    - path: watch_recognition/watch_recognition/train/segmentation_task.py
      md5: 4ac5ac8647443147a73877af03908a12
      size: 9632
    params:
      params.yaml:
        seed: 42
        segmentation:
          epochs: 100
          batch-size: 32
          confidence-threshold: 0.5
    outs:
    - path: debug/segmentation/
      md5: a94bdd87371d35a697d6a0b90dcad565.dir
      size: 410583
      nfiles: 2
    - path: example_predictions/segmentation/test-image-2.jpg
      md5: 9b8d1e5547af6087eebb0090a397ab01
      size: 56009
    - path: metrics/segmentation.json
      md5: 412302d5af89ab0941486f96793a7139
      size: 213
    - path: metrics/segmentation/scalars/
      md5: 7ea4513bb0dca9618b606dfd295bf103.dir
      size: 14955
      nfiles: 4
    - path: models/segmentation/
      md5: 3092355bb88b2e4bdb656c57bd1729dd.dir
      size: 35973303
      nfiles: 5
  eval-end-2-end:
    cmd: python watch_recognition/watch_recognition/eval/end_to_end_eval.py
    deps:
    - path: datasets/watch-faces-local.json
      md5: ff7da7da2e73b2777c9b3d610cab10ff
      size: 1161602
    - path: models/detector
      md5: ac45f8f7bf58e101223826ad8cac9329.dir
      size: 432253678
      nfiles: 5
    - path: models/keypoint
      md5: 4883aa0423b570a75c987fe12917892e.dir
      size: 35988675
      nfiles: 6
    - path: models/segmentation
      md5: 3092355bb88b2e4bdb656c57bd1729dd.dir
      size: 35973303
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/end_to_end_eval.py
      md5: 44b6048e60a21933f13c9b801b7b5792
      size: 7809
    outs:
    - path: metrics/end_2_end_eval.csv
      md5: f040fb57eb98f53cc344638371864dd0
      size: 18230
    - path: metrics/end_2_end_summary.json
      md5: ae7fa01d1ba69960ecf2b37372c52442
      size: 264
  eval-segmentation:
    cmd: python watch_recognition/watch_recognition/eval/segmentation_eval.py --confidence-threshold
      0.5
    deps:
    - path: models/detector/
      md5: ac45f8f7bf58e101223826ad8cac9329.dir
      size: 432253678
      nfiles: 5
    - path: models/segmentation/
      md5: 3092355bb88b2e4bdb656c57bd1729dd.dir
      size: 35973303
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/segmentation_eval.py
      md5: bd04e7ffd7d9d64e4258c38f704171d9
      size: 3342
    outs:
    - path: example_predictions/segmentation/train_0.jpg
      md5: 0defb0322e0fb455707982721e378a81
      size: 47016
    - path: example_predictions/segmentation/train_1.jpg
      md5: d92a132451a2d6a278e4e8da82b368bf
      size: 49072
    - path: example_predictions/segmentation/train_2.jpg
      md5: 0fb2104d383cfee9fdd2b2eb81d5ba2f
      size: 50116
    - path: example_predictions/segmentation/train_3.jpg
      md5: c9e715ab57ca82a71db6453a2f647b3a
      size: 44682
    - path: example_predictions/segmentation/train_4.jpg
      md5: 735d86d30850b45df6e4f2e81b84ce72
      size: 45829
    - path: example_predictions/segmentation/val_0.jpg
      md5: a79e2bf26a95833cb5f9f129466a59cf
      size: 39426
    - path: example_predictions/segmentation/val_1.jpg
      md5: d1191c582af56df6195670351428ddc2
      size: 49272
    - path: example_predictions/segmentation/val_2.jpg
      md5: 1479168dffc8cd4005730a940cc26bb9
      size: 37856
    - path: example_predictions/segmentation/val_3.jpg
      md5: 5326308a5701221bf7cb7c3c0a9c5e90
      size: 47320
    - path: example_predictions/segmentation/val_4.jpg
      md5: 76411332b229adbe085541d19dfa7e67
      size: 41839
