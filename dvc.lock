schema: '2.0'
stages:
  download-images:
    cmd: python scripts/download-images.py datasets/watch-faces.json --concurrent
    deps:
    - path: datasets/watch-faces.json
      md5: 7ae37ef4884d53a136249b1c07f296a1
      size: 1479117
    - path: scripts/download-images.py
      md5: a037cfab1a482a356f1d7d62804041d3
      size: 3961
    outs:
    - path: datasets/test
      md5: e3d2ee519a61c5f5a4579568529d2811.dir
      size: 18637470
      nfiles: 53
    - path: datasets/train
      md5: a03fe551d8055babe79f292255e141a9.dir
      size: 127634809
      nfiles: 301
    - path: datasets/val
      md5: 1ab506f4b22a797ed4afeaf195c51466.dir
      size: 19774777
      nfiles: 40
    - path: datasets/watch-faces-local.json
      md5: 4923448440ffda54529f82097736f85c
      size: 1470055
  train-detector:
    cmd: python watch_recognition/watch_recognition/train/object_detection_task.py  --epochs
      100  --batch-size 16  --seed 42
    deps:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: 396736e163e88b357d8ee13645da3fe5.dir
      size: 119624174
      nfiles: 269
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: 6d8281d60d5ad996ce540f4fe466c8a6
      size: 1278004
    - path: watch_recognition/watch_recognition/train/object_detection_task.py
      md5: e5b158e1ba9fa33d33a5555c4dbb2785
      size: 11006
    params:
      params.yaml:
        detector:
          epochs: 100
          batch-size: 16
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: debug/detector/
      md5: 973730311e0d9aa1d38455c3a468d7f3.dir
      size: 926712
      nfiles: 4
    - path: example_predictions/detector/test-image.jpg
      md5: 2eb36e84cdc676bc843e0fc1fa5f67d0
      size: 128849
    - path: metrics/detector.json
      md5: f2acfead90ee4b0b70c03958771f3182
      size: 474
    - path: metrics/detector/scalars
      md5: b7c2959a26cec5a940b4ee8c33d6c175.dir
      size: 34014
      nfiles: 10
    - path: models/detector/
      md5: 03f56e8ecc95430e957344f6dbb023d9.dir
      size: 432232708
      nfiles: 5
  eval-detector:
    cmd: python watch_recognition/watch_recognition/eval/object_detection_eval.py
    deps:
    - path: models/detector/
      md5: 03f56e8ecc95430e957344f6dbb023d9.dir
      size: 432232708
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/object_detection_eval.py
      md5: 30402100c451819d2f486ffd6fd5d479
      size: 4929
    outs:
    - path: example_predictions/detector/train_0.jpg
      md5: c2144b1e5df86b255e58cfefdbea0491
      size: 65089
    - path: example_predictions/detector/train_1.jpg
      md5: 4a58262d48daf268e96efca0fc4735d0
      size: 37085
    - path: example_predictions/detector/train_2.jpg
      md5: b63fec49190ecea196b6228edbf99c45
      size: 54104
    - path: example_predictions/detector/val_0.jpg
      md5: 2325a4a31fa8587aa832968d4a4ee7ad
      size: 29594
    - path: example_predictions/detector/val_1.jpg
      md5: d5ecd5552e39416e26a8b8b887f9e684
      size: 71624
    - path: example_predictions/detector/val_2.jpg
      md5: b7f2b4ec7d186ea53d3363f70374b87b
      size: 51694
    - path: metrics/detector/PR-IoU@0.50_train.tsv
      md5: 66efd8c6196eae03742579afdfe8dc27
      size: 2441
    - path: metrics/detector/PR-IoU@0.50_val.tsv
      md5: 30490a739bdf77cfc17afbaaf06e761f
      size: 2266
    - path: metrics/detector/PR-IoU@0.75_train.tsv
      md5: 66efd8c6196eae03742579afdfe8dc27
      size: 2441
    - path: metrics/detector/PR-IoU@0.75_val.tsv
      md5: ccb8f56541f99c5874423b1051c84a4b
      size: 1831
    - path: metrics/detector/PR-IoU@0.95_train.tsv
      md5: 7ff55e703011d0f9faaebfefe9ce097f
      size: 1387
    - path: metrics/detector/PR-IoU@0.95_val.tsv
      md5: eb9c22f401e52e662cc9020d738478e0
      size: 1059
    - path: metrics/detector/coco_train.json
      md5: da018981b622802230371afc76fa56a5
      size: 270
    - path: metrics/detector/coco_val.json
      md5: dd7486e4462db49d126156434bcbbaec
      size: 286
  update-metrics:
    cmd: python scripts/update-metrics-table-and-graph.py
    deps:
    - path: metrics
      md5: 29cce0469d14063f1da42974ff4bbc32.dir
      size: 494463
      nfiles: 43
    - path: scripts/update-metrics-table-and-graph.py
      md5: b6166e699fc2111731ce9ebed407e806
      size: 2108
  train-keypoint:
    cmd: python watch_recognition/watch_recognition/train/heatmap_regression_task.py
      --epochs 100 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: 396736e163e88b357d8ee13645da3fe5.dir
      size: 119624174
      nfiles: 269
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: 6d8281d60d5ad996ce540f4fe466c8a6
      size: 1278004
    - path: watch_recognition/watch_recognition/train/heatmap_regression_task.py
      md5: e68e4f6ef260cea287079a8e531c0f9f
      size: 8954
    params:
      params.yaml:
        keypoint:
          epochs: 100
          batch-size: 32
          confidence-threshold: 0.5
          label_to_cls:
            Top: 0
            Center: 1
            Crown: 2
          disk_radius: 5
        max_images:
        seed: 42
    outs:
    - path: debug/keypoint/
      md5: b53b4d6313cf113e5739c42489ff3400.dir
      size: 348096
      nfiles: 2
    - path: example_predictions/keypoint/test-image-2.jpg
      md5: 8b729c79cfcd3ba16d3c07708d3d0983
      size: 66386
    - path: metrics/keypoint.json
      md5: 51a16ddf325390df1d896c8c8d428920
      size: 215
    - path: metrics/keypoint/scalars/
      md5: 1fa3c82fe45e3caa235ef132af3b9597.dir
      size: 14945
      nfiles: 4
    - path: models/keypoint/
      md5: 21da1c54aba030d8b884213565b139d2.dir
      size: 35964730
      nfiles: 6
  eval-keypoint:
    cmd: python watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      --kp-confidence-threshold 0.5
    deps:
    - path: models/detector/
      md5: 03f56e8ecc95430e957344f6dbb023d9.dir
      size: 432232708
      nfiles: 5
    - path: models/keypoint/
      md5: 21da1c54aba030d8b884213565b139d2.dir
      size: 35964730
      nfiles: 6
    - path: watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      md5: 7aee96c16f50bc522e62bc9138f49247
      size: 6302
    outs:
    - path: example_predictions/keypoint/train_0.jpg
      md5: c1ca913e8bd7fce9c0100011e8d31b26
      size: 47946
    - path: example_predictions/keypoint/train_1.jpg
      md5: ac892f4d14757aacd789dafcfb02ac76
      size: 51550
    - path: example_predictions/keypoint/train_2.jpg
      md5: 598a5c07358f69dd472c05e2e01ecca7
      size: 45622
    - path: example_predictions/keypoint/train_3.jpg
      md5: f72abc825c520b5bc068088bc6d43db0
      size: 26527
    - path: example_predictions/keypoint/train_4.jpg
      md5: 859c5fbb62bda96c58ec6545ef6ec2e9
      size: 31873
    - path: example_predictions/keypoint/val_0.jpg
      md5: 28b0b333a1e9a75d6a5bb95de3f924c4
      size: 53323
    - path: example_predictions/keypoint/val_1.jpg
      md5: f59b4b7520cce4ac43ead3a16c858f3a
      size: 60901
    - path: example_predictions/keypoint/val_2.jpg
      md5: ff5b6b7d8f467e8c9f80965ec7948ec8
      size: 48419
    - path: example_predictions/keypoint/val_3.jpg
      md5: 421ba53ada49a09fa89e96aa3059e5a5
      size: 57599
    - path: example_predictions/keypoint/val_4.jpg
      md5: 9a392293940d679972ee07a944421588
      size: 51414
    - path: metrics/keypoint/coco_train.json
      md5: ef212118675051dda7f47d81eb16d256
      size: 262
    - path: metrics/keypoint/coco_val.json
      md5: 246f693b237903136f21788b2506fd67
      size: 260
  train-segmentation:
    cmd: python watch_recognition/watch_recognition/train/segmentation_task.py --epochs
      150 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: datasets/test
      md5: 6904a01888485f56672750554a7bb1e0.dir
      size: 16911707
      nfiles: 46
    - path: datasets/train
      md5: 396736e163e88b357d8ee13645da3fe5.dir
      size: 119624174
      nfiles: 269
    - path: datasets/val
      md5: 97ee700f5d2f812bca96eddc4de09ba5.dir
      size: 17988385
      nfiles: 38
    - path: datasets/watch-faces-local.json
      md5: 6d8281d60d5ad996ce540f4fe466c8a6
      size: 1278004
    - path: watch_recognition/watch_recognition/train/segmentation_task.py
      md5: 42b023a3e7c4eb48cfc62a9bf4833087
      size: 9266
    params:
      params.yaml:
        seed: 42
        segmentation:
          epochs: 150
          batch-size: 32
          confidence-threshold: 0.5
          label_to_cls:
            Hands: 0
          bbox_labels:
          - WatchFace
    outs:
    - path: debug/segmentation/
      md5: f125936e610dda775d1cd3893ba39b69.dir
      size: 745974
      nfiles: 4
    - path: example_predictions/segmentation/test-image-2.jpg
      md5: 7b7c6ec36757383361df91f64e845bc7
      size: 64607
    - path: metrics/segmentation.json
      md5: 17b5714d4f297e15cfc9de6d84e1061d
      size: 215
    - path: metrics/segmentation/scalars/
      md5: 74ee6501aa86d7c2acfcd835535a6f9a.dir
      size: 22594
      nfiles: 4
    - path: models/segmentation/
      md5: 99e3afc26a6a25761f64f3682e283d9c.dir
      size: 35949358
      nfiles: 5
  eval-end-2-end:
    cmd: python watch_recognition/watch_recognition/eval/end_to_end_eval.py --run-concurrently
    deps:
    - path: datasets/watch-faces-local.json
      md5: 6d8281d60d5ad996ce540f4fe466c8a6
      size: 1278004
    - path: models/detector
      md5: 03f56e8ecc95430e957344f6dbb023d9.dir
      size: 432232708
      nfiles: 5
    - path: models/keypoint
      md5: 21da1c54aba030d8b884213565b139d2.dir
      size: 35964730
      nfiles: 6
    - path: models/segmentation
      md5: 99e3afc26a6a25761f64f3682e283d9c.dir
      size: 35949358
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/end_to_end_eval.py
      md5: b8ad67be0dbc2d4f1d3bedc02aa835e5
      size: 8563
    outs:
    - path: metrics/end_2_end_eval.csv
      md5: f9f1a70a0bdb29d190cb7ed7445c2ebc
      size: 24700
    - path: metrics/end_2_end_summary.json
      md5: 5b3be8489e2f768680a3598d3ab85ad1
      size: 263
  eval-segmentation:
    cmd: python watch_recognition/watch_recognition/eval/segmentation_eval.py --confidence-threshold
      0.5
    deps:
    - path: models/detector/
      md5: 03f56e8ecc95430e957344f6dbb023d9.dir
      size: 432232708
      nfiles: 5
    - path: models/segmentation/
      md5: 99e3afc26a6a25761f64f3682e283d9c.dir
      size: 35949358
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/segmentation_eval.py
      md5: bd04e7ffd7d9d64e4258c38f704171d9
      size: 3342
    outs:
    - path: example_predictions/segmentation/train_0.jpg
      md5: a5b14576e2f0f53cbb830568fcf35b56
      size: 46044
    - path: example_predictions/segmentation/train_1.jpg
      md5: 36ce8c779731190434a6492968c5b00f
      size: 45860
    - path: example_predictions/segmentation/train_2.jpg
      md5: 90af39187e3eb2fddf9b514602da824d
      size: 46340
    - path: example_predictions/segmentation/train_3.jpg
      md5: a90eb7ce79ef8fce6c4b9b2f2d8dc181
      size: 34526
    - path: example_predictions/segmentation/train_4.jpg
      md5: 0a1d89f4de8525a1c5ebe4371da8d759
      size: 34720
    - path: example_predictions/segmentation/val_0.jpg
      md5: 16a0dac54fe7347ccf945c1a8acf2990
      size: 44616
    - path: example_predictions/segmentation/val_1.jpg
      md5: f7c2cb2e802bc20014e88e39a94c5186
      size: 56900
    - path: example_predictions/segmentation/val_2.jpg
      md5: 49e829557d5754332e1a221b7d7e841a
      size: 42596
    - path: example_predictions/segmentation/val_3.jpg
      md5: 9afbd24cf9bea377c2b12571a0bae59d
      size: 52873
    - path: example_predictions/segmentation/val_4.jpg
      md5: adf3033fe036c807dd1dab1b54eaa6e4
      size: 48983
