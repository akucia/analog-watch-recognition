schema: '2.0'
stages:
  download-images:
    cmd: python scripts/download-images.py datasets/watch-faces.json --concurrent
    deps:
    - path: datasets/watch-faces.json
      md5: 38c172a71acd5b6b65b2b05a2a724f42
      size: 1758003
    - path: scripts/download-images.py
      md5: a037cfab1a482a356f1d7d62804041d3
      size: 3961
    outs:
    - path: datasets/test
      md5: 0aeb029db40e49068d63308665810b57.dir
      size: 18701099
      nfiles: 54
    - path: datasets/train
      md5: 9c414afa46808b376366ae8e0ff3c786.dir
      size: 170152358
      nfiles: 481
    - path: datasets/val
      md5: 1ab506f4b22a797ed4afeaf195c51466.dir
      size: 19774777
      nfiles: 40
    - path: datasets/watch-faces-local.json
      md5: ddb1e52cb640b1af3e8ba6c7c85c943a
      size: 1744824
  train-detector:
    cmd: python watch_recognition/watch_recognition/train/object_detection_task.py  --epochs
      1  --batch-size 20  --seed 42
    deps:
    - path: datasets/test
      md5: 0aeb029db40e49068d63308665810b57.dir
      size: 18701099
      nfiles: 54
    - path: datasets/train
      md5: 9c414afa46808b376366ae8e0ff3c786.dir
      size: 170152358
      nfiles: 481
    - path: datasets/val
      md5: 1ab506f4b22a797ed4afeaf195c51466.dir
      size: 19774777
      nfiles: 40
    - path: datasets/watch-faces-local.json
      md5: ddb1e52cb640b1af3e8ba6c7c85c943a
      size: 1744824
    - path: watch_recognition/watch_recognition/train/object_detection_task.py
      md5: d9041dfe06970095d1a331f9cb8c22e2
      size: 11056
    params:
      params.yaml:
        detector:
          epochs: 1
          batch-size: 20
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: debug/detector/
      md5: f0064e0537be8585bdbe1a4f53d07a42.dir
      size: 950728
      nfiles: 4
    - path: example_predictions/detector/test-image.jpg
      md5: 753f27c86ade589ba2b889e6c2b0fe65
      size: 142855
    - path: metrics/detector/metrics.json
      md5: 08def9779a8fafd2a854a5fd171c8a24
      size: 476
    - path: metrics/detector/plots
      md5: 166a55f770c4f1085df8278629c5dbdb.dir
      size: 422
      nfiles: 10
    - path: models/detector/
      md5: 9b6fb65a98ec61423ed69b8822a11986.dir
      size: 432220709
      nfiles: 5
  eval-detector:
    cmd: python watch_recognition/watch_recognition/eval/object_detection_eval.py
    deps:
    - path: models/detector/
      md5: 1fab3506112358531d4e67f67318d577.dir
      size: 432232708
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/object_detection_eval.py
      md5: 30402100c451819d2f486ffd6fd5d479
      size: 4929
    outs:
    - path: example_predictions/detector/train_0.jpg
      md5: 93931095077f867a3609ca5cc350785d
      size: 50650
    - path: example_predictions/detector/train_1.jpg
      md5: b2b6dbdaffe4dfe8bd71bf3367f93db4
      size: 31230
    - path: example_predictions/detector/train_2.jpg
      md5: 5d616b00d49eff0b7296a5320a6d9768
      size: 29634
    - path: example_predictions/detector/val_0.jpg
      md5: 5e8b94f83c57e43cf6b3763025b16047
      size: 24744
    - path: example_predictions/detector/val_1.jpg
      md5: 8e75764bb7fd5ec6f18b8ae6e5bffa66
      size: 57159
    - path: example_predictions/detector/val_2.jpg
      md5: 98571413ffd7c5d3193d0e41e4e477da
      size: 41054
    - path: metrics/detector/PR-IoU@0.50_train.tsv
      md5: d6d6ffe1d048359ec1370d67524e26ca
      size: 2446
    - path: metrics/detector/PR-IoU@0.50_val.tsv
      md5: 2ca42f02c389fad2622e8193d2b74353
      size: 2101
    - path: metrics/detector/PR-IoU@0.75_train.tsv
      md5: 29490fef8eb8e05ecdc1b77aa2adbc48
      size: 2431
    - path: metrics/detector/PR-IoU@0.75_val.tsv
      md5: 4ccb2f76b247b1c2e5fcef43228a7e71
      size: 2059
    - path: metrics/detector/PR-IoU@0.95_train.tsv
      md5: c5d9820ba58c54d3485dad7dbc8edfd3
      size: 1415
    - path: metrics/detector/PR-IoU@0.95_val.tsv
      md5: eb9c22f401e52e662cc9020d738478e0
      size: 1059
    - path: metrics/detector/coco_train.json
      md5: 5c593cb7919cae59dc9a42f690ad72fc
      size: 285
    - path: metrics/detector/coco_val.json
      md5: 22b3e9f9f5252c89516516a616013653
      size: 270
  update-metrics:
    cmd: python scripts/update-metrics-table-and-graph.py
    deps:
    - path: metrics
      md5: 0f0aa73552c12aed88a9fcd7d9600bd1.dir
      size: 476006
      nfiles: 43
    - path: scripts/update-metrics-table-and-graph.py
      md5: b6166e699fc2111731ce9ebed407e806
      size: 2108
  train-keypoint:
    cmd: python watch_recognition/watch_recognition/train/heatmap_regression_task.py
      --epochs 100 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: datasets/test
      md5: 0aeb029db40e49068d63308665810b57.dir
      size: 18701099
      nfiles: 54
    - path: datasets/train
      md5: 9c414afa46808b376366ae8e0ff3c786.dir
      size: 170152358
      nfiles: 481
    - path: datasets/val
      md5: 1ab506f4b22a797ed4afeaf195c51466.dir
      size: 19774777
      nfiles: 40
    - path: datasets/watch-faces-local.json
      md5: ddb1e52cb640b1af3e8ba6c7c85c943a
      size: 1744824
    - path: watch_recognition/watch_recognition/train/heatmap_regression_task.py
      md5: f6a86273f89a38a8abdb8575ec154e9d
      size: 8953
    params:
      params.yaml:
        keypoint:
          epochs: 100
          batch-size: 32
          confidence-threshold: 0.5
          label_to_cls:
            Top: 0
            Center: 1
            Crown: 2
          disk_radius: 5
        max_images:
        seed: 42
    outs:
    - path: debug/keypoint/
      md5: 2ac270cd02a60722351bada220d03d8c.dir
      size: 399737
      nfiles: 2
    - path: example_predictions/keypoint/test-image-2.jpg
      md5: 89d44b8cb435b07ac4634e13eaa00860
      size: 66334
    - path: metrics/keypoint/metrics.json
      md5: c479e42ab5fdf1aa00041a9ea746728e
      size: 214
    - path: metrics/keypoint/plots/
      md5: c6572a9c857b01e34dc8b7b1bc49ff3c.dir
      size: 8908
      nfiles: 4
    - path: models/keypoint/
      md5: 4a34792d0d5209c621c38464f1614818.dir
      size: 35988621
      nfiles: 6
  eval-keypoint:
    cmd: python watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      --kp-confidence-threshold 0.5
    deps:
    - path: models/detector/
      md5: 1fab3506112358531d4e67f67318d577.dir
      size: 432232708
      nfiles: 5
    - path: models/keypoint/
      md5: 61e3f9286fc1eb9530e2878629990abc.dir
      size: 35964730
      nfiles: 6
    - path: watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      md5: 7aee96c16f50bc522e62bc9138f49247
      size: 6302
    outs:
    - path: example_predictions/keypoint/train_0.jpg
      md5: 065902c4224d6e4ded2ffd5eb1c5fb2d
      size: 25458
    - path: example_predictions/keypoint/train_1.jpg
      md5: 87be1633d4e2629e598184dbafd5dc90
      size: 21951
    - path: example_predictions/keypoint/train_2.jpg
      md5: f092b0e3656b1527980d3f5ee4472c4a
      size: 42166
    - path: example_predictions/keypoint/train_3.jpg
      md5: b0e9da65d6eb0f0d881d395ab00daae6
      size: 38041
    - path: example_predictions/keypoint/train_4.jpg
      md5: 6ec1e284d155bb0795063726e8ef81af
      size: 37605
    - path: example_predictions/keypoint/val_0.jpg
      md5: f4233d485b75ab4fa2c6ddf7b09af9d7
      size: 53245
    - path: example_predictions/keypoint/val_1.jpg
      md5: f3872f5c07a702cfd6667dc2d399fc21
      size: 60953
    - path: example_predictions/keypoint/val_2.jpg
      md5: e688033fb3d853f1812251060dca598b
      size: 48369
    - path: example_predictions/keypoint/val_3.jpg
      md5: 571341fd9f985c0e7be89ea985e9fe93
      size: 57673
    - path: example_predictions/keypoint/val_4.jpg
      md5: 3ede96a954d7b20bb21a9a9f2a4d8621
      size: 51549
    - path: metrics/keypoint/coco_train.json
      md5: 4c4fdf89b72a329b4e0b47985bf12a9e
      size: 260
    - path: metrics/keypoint/coco_val.json
      md5: fad55e8d91734f2d590a026e55746447
      size: 248
  train-segmentation:
    cmd: python watch_recognition/watch_recognition/train/segmentation_task.py --epochs
      150 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: datasets/test
      md5: 0aeb029db40e49068d63308665810b57.dir
      size: 18701099
      nfiles: 54
    - path: datasets/train
      md5: 9c414afa46808b376366ae8e0ff3c786.dir
      size: 170152358
      nfiles: 481
    - path: datasets/val
      md5: 1ab506f4b22a797ed4afeaf195c51466.dir
      size: 19774777
      nfiles: 40
    - path: datasets/watch-faces-local.json
      md5: ddb1e52cb640b1af3e8ba6c7c85c943a
      size: 1744824
    - path: watch_recognition/watch_recognition/train/segmentation_task.py
      md5: af4c58046894343dd442a39bbfbd6411
      size: 9265
    params:
      params.yaml:
        seed: 42
        segmentation:
          epochs: 150
          batch-size: 32
          confidence-threshold: 0.5
          label_to_cls:
            Hands: 0
          bbox_labels:
          - WatchFace
    outs:
    - path: debug/segmentation/
      md5: 78f6047cbb06c4e7889f881f7143064d.dir
      size: 761590
      nfiles: 4
    - path: example_predictions/segmentation/test-image-2.jpg
      md5: 44fc2994fb44e280363c023622c24163
      size: 64278
    - path: metrics/segmentation/metrics.json
      md5: ed15dc7ca524e01ef350507b0f8cda43
      size: 215
    - path: metrics/segmentation/plots/
      md5: e0203589dc6763f0c85af5d7f2eee974.dir
      size: 13572
      nfiles: 4
    - path: models/segmentation/
      md5: 986e39bc0071d95599ee1918c760865c.dir
      size: 35949342
      nfiles: 5
  eval-end-2-end:
    cmd: python watch_recognition/watch_recognition/eval/end_to_end_eval.py --run-concurrently
      --split=val
    deps:
    - path: datasets/watch-faces-local.json
      md5: b70283f3027b17d5c33f72fe0685e3a5
      size: 1573168
    - path: models/detector
      md5: 1fab3506112358531d4e67f67318d577.dir
      size: 432232708
      nfiles: 5
    - path: models/keypoint
      md5: 61e3f9286fc1eb9530e2878629990abc.dir
      size: 35964730
      nfiles: 6
    - path: models/segmentation
      md5: e603288dbbd9abdd9725e917d2b4ff50.dir
      size: 35949358
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/end_to_end_eval.py
      md5: c48df0afed288ec1b487fc2088b43b86
      size: 8652
    outs:
    - path: metrics/end_2_end_eval.csv
      md5: 760a2cbeead50d05ac8874d97761747a
      size: 5955
    - path: metrics/end_2_end_summary.json
      md5: efa5cc3780b031a247ae9dc26e7daa39
      size: 132
  eval-segmentation:
    cmd: python watch_recognition/watch_recognition/eval/segmentation_eval.py --confidence-threshold
      0.5
    deps:
    - path: models/detector/
      md5: 1fab3506112358531d4e67f67318d577.dir
      size: 432232708
      nfiles: 5
    - path: models/segmentation/
      md5: e603288dbbd9abdd9725e917d2b4ff50.dir
      size: 35949358
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/segmentation_eval.py
      md5: bd04e7ffd7d9d64e4258c38f704171d9
      size: 3342
    outs:
    - path: example_predictions/segmentation/train_0.jpg
      md5: 6a8b958272c7a526ac7cc8e817c36819
      size: 38057
    - path: example_predictions/segmentation/train_1.jpg
      md5: 42a99756851e8bea3b2ec4d1b1101373
      size: 33152
    - path: example_predictions/segmentation/train_2.jpg
      md5: 29da582aa4fc9b6baf59596f46e66265
      size: 70663
    - path: example_predictions/segmentation/train_3.jpg
      md5: 9f65e08f3eb01b7efe4154af09cc38f7
      size: 62474
    - path: example_predictions/segmentation/train_4.jpg
      md5: 743c36a60a214db5fee5c953daecb2fc
      size: 60865
    - path: example_predictions/segmentation/val_0.jpg
      md5: 1ca6d0abd458aeee64a815f278814bd2
      size: 54061
    - path: example_predictions/segmentation/val_1.jpg
      md5: 3f4ef24a968bc46eac0df4bcc71ed9b0
      size: 69317
    - path: example_predictions/segmentation/val_2.jpg
      md5: 440e19279165882404ca7e0b4005a0d1
      size: 52297
    - path: example_predictions/segmentation/val_3.jpg
      md5: fc8d3e5df328fa4ed83d4f14a6644dfb
      size: 64612
    - path: example_predictions/segmentation/val_4.jpg
      md5: 33d3e534de1ad6eef76464d8e2c184d2
      size: 59440
