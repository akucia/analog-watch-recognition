schema: '2.0'
stages:
  download-images:
    cmd: python scripts/download-images.py datasets/watch-faces.json --concurrent
    deps:
    - path: datasets/watch-faces.json
      md5: e511ace3540e21fa6aca6488ec60cc9f
      size: 1583564
    - path: scripts/download-images.py
      md5: a037cfab1a482a356f1d7d62804041d3
      size: 3961
    outs:
    - path: datasets/test
      md5: e3d2ee519a61c5f5a4579568529d2811.dir
      size: 18637470
      nfiles: 53
    - path: datasets/train
      md5: 28f07f73f06d2e0befe195550531c835.dir
      size: 136597936
      nfiles: 347
    - path: datasets/val
      md5: 1ab506f4b22a797ed4afeaf195c51466.dir
      size: 19774777
      nfiles: 40
    - path: datasets/watch-faces-local.json
      md5: e79bba76820001ad159be82633d6d1b9
      size: 1573490
  train-detector:
    cmd: python watch_recognition/watch_recognition/train/object_detection_task.py  --epochs
      100  --batch-size 16  --seed 42
    deps:
    - path: datasets/test
      md5: e3d2ee519a61c5f5a4579568529d2811.dir
      size: 18637470
      nfiles: 53
    - path: datasets/train
      md5: 28f07f73f06d2e0befe195550531c835.dir
      size: 136597936
      nfiles: 347
    - path: datasets/val
      md5: 1ab506f4b22a797ed4afeaf195c51466.dir
      size: 19774777
      nfiles: 40
    - path: datasets/watch-faces-local.json
      md5: e79bba76820001ad159be82633d6d1b9
      size: 1573490
    - path: watch_recognition/watch_recognition/train/object_detection_task.py
      md5: e5b158e1ba9fa33d33a5555c4dbb2785
      size: 11006
    params:
      params.yaml:
        detector:
          epochs: 100
          batch-size: 16
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: debug/detector/
      md5: 897e041107398cda6254eb3753628337.dir
      size: 946026
      nfiles: 4
    - path: example_predictions/detector/test-image.jpg
      md5: 5878c6dea61b7e272fb75b953eb1d475
      size: 128972
    - path: metrics/detector.json
      md5: 8a8766677fb5316a25ecb8782d1d635d
      size: 476
    - path: metrics/detector/scalars
      md5: 82e007c4cabaeebd69f6b1d8bc9d694c.dir
      size: 34073
      nfiles: 10
    - path: models/detector/
      md5: 7a3e024211ac912498bf26c4a9f3316f.dir
      size: 432232708
      nfiles: 5
  eval-detector:
    cmd: python watch_recognition/watch_recognition/eval/object_detection_eval.py
    deps:
    - path: models/detector/
      md5: 7a3e024211ac912498bf26c4a9f3316f.dir
      size: 432232708
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/object_detection_eval.py
      md5: 30402100c451819d2f486ffd6fd5d479
      size: 4929
    outs:
    - path: example_predictions/detector/train_0.jpg
      md5: 1bcc7b7ca6972ee218b2a0283a3713d9
      size: 61688
    - path: example_predictions/detector/train_1.jpg
      md5: 47e1ff23ce6a79fc8ff5c91650fcccf3
      size: 37356
    - path: example_predictions/detector/train_2.jpg
      md5: c7cbfda18ed5d5824288dda522ff2be2
      size: 36663
    - path: example_predictions/detector/val_0.jpg
      md5: 3eea7b61e746219f1bde1120cd516df7
      size: 29467
    - path: example_predictions/detector/val_1.jpg
      md5: 1f3887e8f72ba714ba99fd29c36c9044
      size: 71325
    - path: example_predictions/detector/val_2.jpg
      md5: 69460d4fda1f6a184d93e218a0ba1373
      size: 51768
    - path: metrics/detector/PR-IoU@0.50_train.tsv
      md5: eeec40a25c32f8ddcb8094d83a5c8279
      size: 2458
    - path: metrics/detector/PR-IoU@0.50_val.tsv
      md5: 8f710052c91aff9162a6b499b4881a54
      size: 1830
    - path: metrics/detector/PR-IoU@0.75_train.tsv
      md5: 5fe9fb95b396f8f6cc847f5f1c46f585
      size: 2443
    - path: metrics/detector/PR-IoU@0.75_val.tsv
      md5: faba59a71d88b8a041bceba63cf7d691
      size: 1545
    - path: metrics/detector/PR-IoU@0.95_train.tsv
      md5: 989db0554c105587aa76659afc17acce
      size: 1466
    - path: metrics/detector/PR-IoU@0.95_val.tsv
      md5: eb9c22f401e52e662cc9020d738478e0
      size: 1059
    - path: metrics/detector/coco_train.json
      md5: b6611aa715a0a4514ae7730b56eeacbb
      size: 281
    - path: metrics/detector/coco_val.json
      md5: 02c312ecccb25845bb0ade01800a8208
      size: 286
  update-metrics:
    cmd: python scripts/update-metrics-table-and-graph.py
    deps:
    - path: metrics
      md5: 29cce0469d14063f1da42974ff4bbc32.dir
      size: 494463
      nfiles: 43
    - path: scripts/update-metrics-table-and-graph.py
      md5: b6166e699fc2111731ce9ebed407e806
      size: 2108
  train-keypoint:
    cmd: python watch_recognition/watch_recognition/train/heatmap_regression_task.py
      --epochs 100 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: datasets/test
      md5: e3d2ee519a61c5f5a4579568529d2811.dir
      size: 18637470
      nfiles: 53
    - path: datasets/train
      md5: 28f07f73f06d2e0befe195550531c835.dir
      size: 136597936
      nfiles: 347
    - path: datasets/val
      md5: 1ab506f4b22a797ed4afeaf195c51466.dir
      size: 19774777
      nfiles: 40
    - path: datasets/watch-faces-local.json
      md5: e79bba76820001ad159be82633d6d1b9
      size: 1573490
    - path: watch_recognition/watch_recognition/train/heatmap_regression_task.py
      md5: e68e4f6ef260cea287079a8e531c0f9f
      size: 8954
    params:
      params.yaml:
        keypoint:
          epochs: 100
          batch-size: 32
          confidence-threshold: 0.5
          label_to_cls:
            Top: 0
            Center: 1
            Crown: 2
          disk_radius: 5
        max_images:
        seed: 42
    outs:
    - path: debug/keypoint/
      md5: 30a92b7d02116ab579b9e2037ca858b1.dir
      size: 380741
      nfiles: 2
    - path: example_predictions/keypoint/test-image-2.jpg
      md5: 5ab7288ef65b2fd6d62791d749721f58
      size: 66389
    - path: metrics/keypoint.json
      md5: f0a0b5e77bdca6f7b2f52b87361f97a4
      size: 213
    - path: metrics/keypoint/scalars/
      md5: 3720c34ff7bd1de25da8461d4192a1da.dir
      size: 14923
      nfiles: 4
    - path: models/keypoint/
      md5: 50daab5812eecb112f562cdbba8f68f5.dir
      size: 35964730
      nfiles: 6
  eval-keypoint:
    cmd: python watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      --kp-confidence-threshold 0.5
    deps:
    - path: models/detector/
      md5: 03f56e8ecc95430e957344f6dbb023d9.dir
      size: 432232708
      nfiles: 5
    - path: models/keypoint/
      md5: 21da1c54aba030d8b884213565b139d2.dir
      size: 35964730
      nfiles: 6
    - path: watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      md5: 7aee96c16f50bc522e62bc9138f49247
      size: 6302
    outs:
    - path: example_predictions/keypoint/train_0.jpg
      md5: c1ca913e8bd7fce9c0100011e8d31b26
      size: 47946
    - path: example_predictions/keypoint/train_1.jpg
      md5: ac892f4d14757aacd789dafcfb02ac76
      size: 51550
    - path: example_predictions/keypoint/train_2.jpg
      md5: 598a5c07358f69dd472c05e2e01ecca7
      size: 45622
    - path: example_predictions/keypoint/train_3.jpg
      md5: f72abc825c520b5bc068088bc6d43db0
      size: 26527
    - path: example_predictions/keypoint/train_4.jpg
      md5: 859c5fbb62bda96c58ec6545ef6ec2e9
      size: 31873
    - path: example_predictions/keypoint/val_0.jpg
      md5: 28b0b333a1e9a75d6a5bb95de3f924c4
      size: 53323
    - path: example_predictions/keypoint/val_1.jpg
      md5: f59b4b7520cce4ac43ead3a16c858f3a
      size: 60901
    - path: example_predictions/keypoint/val_2.jpg
      md5: ff5b6b7d8f467e8c9f80965ec7948ec8
      size: 48419
    - path: example_predictions/keypoint/val_3.jpg
      md5: 421ba53ada49a09fa89e96aa3059e5a5
      size: 57599
    - path: example_predictions/keypoint/val_4.jpg
      md5: 9a392293940d679972ee07a944421588
      size: 51414
    - path: metrics/keypoint/coco_train.json
      md5: ef212118675051dda7f47d81eb16d256
      size: 262
    - path: metrics/keypoint/coco_val.json
      md5: 246f693b237903136f21788b2506fd67
      size: 260
  train-segmentation:
    cmd: python watch_recognition/watch_recognition/train/segmentation_task.py --epochs
      150 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: datasets/test
      md5: e3d2ee519a61c5f5a4579568529d2811.dir
      size: 18637470
      nfiles: 53
    - path: datasets/train
      md5: 28f07f73f06d2e0befe195550531c835.dir
      size: 136597936
      nfiles: 347
    - path: datasets/val
      md5: 1ab506f4b22a797ed4afeaf195c51466.dir
      size: 19774777
      nfiles: 40
    - path: datasets/watch-faces-local.json
      md5: e79bba76820001ad159be82633d6d1b9
      size: 1573490
    - path: watch_recognition/watch_recognition/train/segmentation_task.py
      md5: 42b023a3e7c4eb48cfc62a9bf4833087
      size: 9266
    params:
      params.yaml:
        seed: 42
        segmentation:
          epochs: 150
          batch-size: 32
          confidence-threshold: 0.5
          label_to_cls:
            Hands: 0
          bbox_labels:
          - WatchFace
    outs:
    - path: debug/segmentation/
      md5: 1126ed38e98ed951f930ef7176568063.dir
      size: 759519
      nfiles: 4
    - path: example_predictions/segmentation/test-image-2.jpg
      md5: ffa130f85dd32a6221fdac1faae2f9ab
      size: 64294
    - path: metrics/segmentation.json
      md5: 02a5adae8ff8fa55169e74e870e41d65
      size: 213
    - path: metrics/segmentation/scalars/
      md5: bc3d71e4610e729cea3db2f694fa8056.dir
      size: 22616
      nfiles: 4
    - path: models/segmentation/
      md5: 226fea3a2fa41377d37c4bab8ddc4ee7.dir
      size: 35949358
      nfiles: 5
  eval-end-2-end:
    cmd: python watch_recognition/watch_recognition/eval/end_to_end_eval.py --run-concurrently
    deps:
    - path: datasets/watch-faces-local.json
      md5: 6d8281d60d5ad996ce540f4fe466c8a6
      size: 1278004
    - path: models/detector
      md5: 03f56e8ecc95430e957344f6dbb023d9.dir
      size: 432232708
      nfiles: 5
    - path: models/keypoint
      md5: 21da1c54aba030d8b884213565b139d2.dir
      size: 35964730
      nfiles: 6
    - path: models/segmentation
      md5: 99e3afc26a6a25761f64f3682e283d9c.dir
      size: 35949358
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/end_to_end_eval.py
      md5: b8ad67be0dbc2d4f1d3bedc02aa835e5
      size: 8563
    outs:
    - path: metrics/end_2_end_eval.csv
      md5: f9f1a70a0bdb29d190cb7ed7445c2ebc
      size: 24700
    - path: metrics/end_2_end_summary.json
      md5: 5b3be8489e2f768680a3598d3ab85ad1
      size: 263
  eval-segmentation:
    cmd: python watch_recognition/watch_recognition/eval/segmentation_eval.py --confidence-threshold
      0.5
    deps:
    - path: models/detector/
      md5: 7a3e024211ac912498bf26c4a9f3316f.dir
      size: 432232708
      nfiles: 5
    - path: models/segmentation/
      md5: 226fea3a2fa41377d37c4bab8ddc4ee7.dir
      size: 35949358
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/segmentation_eval.py
      md5: bd04e7ffd7d9d64e4258c38f704171d9
      size: 3342
    outs:
    - path: example_predictions/segmentation/train_0.jpg
      md5: b00b80455a3374609c927d71faaea810
      size: 38113
    - path: example_predictions/segmentation/train_1.jpg
      md5: a636d18964b1516b62e34aaed8d7569b
      size: 33299
    - path: example_predictions/segmentation/train_2.jpg
      md5: 1b010c077c5b9bcb20822c07c10d09c9
      size: 70683
    - path: example_predictions/segmentation/train_3.jpg
      md5: 2e33ad7144947ef1dd9a70e11c463c33
      size: 62432
    - path: example_predictions/segmentation/train_4.jpg
      md5: 82cb774dd69610539d51a9d09d031c23
      size: 60894
    - path: example_predictions/segmentation/val_0.jpg
      md5: 0ea4903575dd8506403030d2eb22817c
      size: 54192
    - path: example_predictions/segmentation/val_1.jpg
      md5: 44724d1ddabea81c5fa965bec595dc1d
      size: 69352
    - path: example_predictions/segmentation/val_2.jpg
      md5: 9d2417ff2d805467449bd9facad920b5
      size: 52175
    - path: example_predictions/segmentation/val_3.jpg
      md5: 0c9800c3d4bdfee89255b7a7eaeedd5c
      size: 64705
    - path: example_predictions/segmentation/val_4.jpg
      md5: 91437b1ee5b967bc93c2f667f89957d4
      size: 59479
