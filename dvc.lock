schema: '2.0'
stages:
  download-images:
    cmd: python scripts/download-images.py datasets/watch-faces.json --concurrent
    deps:
    - path: datasets/watch-faces.json
      md5: 68cc3a368e8efbb6fd98f69d7052ea89
      size: 1583242
    - path: scripts/download-images.py
      md5: a037cfab1a482a356f1d7d62804041d3
      size: 3961
    outs:
    - path: datasets/test
      md5: e3d2ee519a61c5f5a4579568529d2811.dir
      size: 18637470
      nfiles: 53
    - path: datasets/train
      md5: 28f07f73f06d2e0befe195550531c835.dir
      size: 136597936
      nfiles: 347
    - path: datasets/val
      md5: 1ab506f4b22a797ed4afeaf195c51466.dir
      size: 19774777
      nfiles: 40
    - path: datasets/watch-faces-local.json
      md5: b70283f3027b17d5c33f72fe0685e3a5
      size: 1573168
  train-detector:
    cmd: python watch_recognition/watch_recognition/train/object_detection_task.py  --epochs
      100  --batch-size 16  --seed 42
    deps:
    - path: datasets/test
      md5: e3d2ee519a61c5f5a4579568529d2811.dir
      size: 18637470
      nfiles: 53
    - path: datasets/train
      md5: 28f07f73f06d2e0befe195550531c835.dir
      size: 136597936
      nfiles: 347
    - path: datasets/val
      md5: 1ab506f4b22a797ed4afeaf195c51466.dir
      size: 19774777
      nfiles: 40
    - path: datasets/watch-faces-local.json
      md5: b70283f3027b17d5c33f72fe0685e3a5
      size: 1573168
    - path: watch_recognition/watch_recognition/train/object_detection_task.py
      md5: 27c40eae990bc1893dc86b8c346ce690
      size: 11057
    params:
      params.yaml:
        detector:
          epochs: 100
          batch-size: 16
          confidence-threshold: 0.5
        seed: 42
    outs:
    - path: debug/detector/
      md5: d392c1ac3e579621f39adef8dd682265.dir
      size: 971686
      nfiles: 4
    - path: example_predictions/detector/test-image.jpg
      md5: 3301315581f650bfca77e563487eb5dc
      size: 129446
    - path: metrics/detector.json
      md5: 7ce39108312d2b28f8171981381e4151
      size: 473
    - path: metrics/detector/scalars
      md5: f84b1d2eb1288f2c80270ef07e71e4f1.dir
      size: 34207
      nfiles: 10
    - path: models/detector/
      md5: 1fab3506112358531d4e67f67318d577.dir
      size: 432232708
      nfiles: 5
  eval-detector:
    cmd: python watch_recognition/watch_recognition/eval/object_detection_eval.py
    deps:
    - path: models/detector/
      md5: 1fab3506112358531d4e67f67318d577.dir
      size: 432232708
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/object_detection_eval.py
      md5: 30402100c451819d2f486ffd6fd5d479
      size: 4929
    outs:
    - path: example_predictions/detector/train_0.jpg
      md5: 93931095077f867a3609ca5cc350785d
      size: 50650
    - path: example_predictions/detector/train_1.jpg
      md5: b2b6dbdaffe4dfe8bd71bf3367f93db4
      size: 31230
    - path: example_predictions/detector/train_2.jpg
      md5: 5d616b00d49eff0b7296a5320a6d9768
      size: 29634
    - path: example_predictions/detector/val_0.jpg
      md5: 5e8b94f83c57e43cf6b3763025b16047
      size: 24744
    - path: example_predictions/detector/val_1.jpg
      md5: 8e75764bb7fd5ec6f18b8ae6e5bffa66
      size: 57159
    - path: example_predictions/detector/val_2.jpg
      md5: 98571413ffd7c5d3193d0e41e4e477da
      size: 41054
    - path: metrics/detector/PR-IoU@0.50_train.tsv
      md5: d6d6ffe1d048359ec1370d67524e26ca
      size: 2446
    - path: metrics/detector/PR-IoU@0.50_val.tsv
      md5: 2ca42f02c389fad2622e8193d2b74353
      size: 2101
    - path: metrics/detector/PR-IoU@0.75_train.tsv
      md5: 29490fef8eb8e05ecdc1b77aa2adbc48
      size: 2431
    - path: metrics/detector/PR-IoU@0.75_val.tsv
      md5: 4ccb2f76b247b1c2e5fcef43228a7e71
      size: 2059
    - path: metrics/detector/PR-IoU@0.95_train.tsv
      md5: c5d9820ba58c54d3485dad7dbc8edfd3
      size: 1415
    - path: metrics/detector/PR-IoU@0.95_val.tsv
      md5: eb9c22f401e52e662cc9020d738478e0
      size: 1059
    - path: metrics/detector/coco_train.json
      md5: 5c593cb7919cae59dc9a42f690ad72fc
      size: 285
    - path: metrics/detector/coco_val.json
      md5: 22b3e9f9f5252c89516516a616013653
      size: 270
  update-metrics:
    cmd: python scripts/update-metrics-table-and-graph.py
    deps:
    - path: metrics
      md5: 297bb992f48d2448ce929c4ba4e72546.dir
      size: 476016
      nfiles: 43
    - path: scripts/update-metrics-table-and-graph.py
      md5: b6166e699fc2111731ce9ebed407e806
      size: 2108
  train-keypoint:
    cmd: python watch_recognition/watch_recognition/train/heatmap_regression_task.py
      --epochs 100 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: datasets/test
      md5: e3d2ee519a61c5f5a4579568529d2811.dir
      size: 18637470
      nfiles: 53
    - path: datasets/train
      md5: 28f07f73f06d2e0befe195550531c835.dir
      size: 136597936
      nfiles: 347
    - path: datasets/val
      md5: 1ab506f4b22a797ed4afeaf195c51466.dir
      size: 19774777
      nfiles: 40
    - path: datasets/watch-faces-local.json
      md5: e79bba76820001ad159be82633d6d1b9
      size: 1573490
    - path: watch_recognition/watch_recognition/train/heatmap_regression_task.py
      md5: e68e4f6ef260cea287079a8e531c0f9f
      size: 8954
    params:
      params.yaml:
        keypoint:
          epochs: 100
          batch-size: 32
          confidence-threshold: 0.5
          label_to_cls:
            Top: 0
            Center: 1
            Crown: 2
          disk_radius: 5
        max_images:
        seed: 42
    outs:
    - path: debug/keypoint/
      md5: 30a92b7d02116ab579b9e2037ca858b1.dir
      size: 380741
      nfiles: 2
    - path: example_predictions/keypoint/test-image-2.jpg
      md5: 5ab7288ef65b2fd6d62791d749721f58
      size: 66389
    - path: metrics/keypoint.json
      md5: f0a0b5e77bdca6f7b2f52b87361f97a4
      size: 213
    - path: metrics/keypoint/scalars/
      md5: 3720c34ff7bd1de25da8461d4192a1da.dir
      size: 14923
      nfiles: 4
    - path: models/keypoint/
      md5: 50daab5812eecb112f562cdbba8f68f5.dir
      size: 35964730
      nfiles: 6
  eval-keypoint:
    cmd: python watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      --kp-confidence-threshold 0.5
    deps:
    - path: models/detector/
      md5: 1fab3506112358531d4e67f67318d577.dir
      size: 432232708
      nfiles: 5
    - path: models/keypoint/
      md5: 50daab5812eecb112f562cdbba8f68f5.dir
      size: 35964730
      nfiles: 6
    - path: watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      md5: 7aee96c16f50bc522e62bc9138f49247
      size: 6302
    outs:
    - path: example_predictions/keypoint/train_0.jpg
      md5: 2cdc24804f33ef3c2e3909f342624a75
      size: 25505
    - path: example_predictions/keypoint/train_1.jpg
      md5: da93865ea89848ecfb59fbdc718f956a
      size: 21968
    - path: example_predictions/keypoint/train_2.jpg
      md5: 1023ebf8b6c39d2bd3efe8ad90d79259
      size: 42161
    - path: example_predictions/keypoint/train_3.jpg
      md5: bd921d1595503cc5f63868e6baa2b121
      size: 38043
    - path: example_predictions/keypoint/train_4.jpg
      md5: 027a85fe3dee11ce551f811b7df2a19c
      size: 37734
    - path: example_predictions/keypoint/val_0.jpg
      md5: b5a92907ee356b9fdf55bf084cb8b08d
      size: 53393
    - path: example_predictions/keypoint/val_1.jpg
      md5: 08b979c1ea8f864370d58d948f9be822
      size: 60940
    - path: example_predictions/keypoint/val_2.jpg
      md5: f4479a7e6379c380aa8cdc6399f65ccd
      size: 48338
    - path: example_predictions/keypoint/val_3.jpg
      md5: 97b65427f3ef789ccbdb6df2b6528c26
      size: 57605
    - path: example_predictions/keypoint/val_4.jpg
      md5: d45e724b566199bad5a0c915faddd300
      size: 51468
    - path: metrics/keypoint/coco_train.json
      md5: 1abf2b6da38435bfbce62c5954091675
      size: 263
    - path: metrics/keypoint/coco_val.json
      md5: 2d158feadfbcd83922bda2b2de054e58
      size: 259
  train-segmentation:
    cmd: python watch_recognition/watch_recognition/train/segmentation_task.py --epochs
      150 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: datasets/test
      md5: e3d2ee519a61c5f5a4579568529d2811.dir
      size: 18637470
      nfiles: 53
    - path: datasets/train
      md5: 28f07f73f06d2e0befe195550531c835.dir
      size: 136597936
      nfiles: 347
    - path: datasets/val
      md5: 1ab506f4b22a797ed4afeaf195c51466.dir
      size: 19774777
      nfiles: 40
    - path: datasets/watch-faces-local.json
      md5: b70283f3027b17d5c33f72fe0685e3a5
      size: 1573168
    - path: watch_recognition/watch_recognition/train/segmentation_task.py
      md5: 42b023a3e7c4eb48cfc62a9bf4833087
      size: 9266
    params:
      params.yaml:
        seed: 42
        segmentation:
          epochs: 150
          batch-size: 32
          confidence-threshold: 0.5
          label_to_cls:
            Hands: 0
          bbox_labels:
          - WatchFace
    outs:
    - path: debug/segmentation/
      md5: 24afd9340454a064d6cd761ab4fa8b2e.dir
      size: 739943
      nfiles: 4
    - path: example_predictions/segmentation/test-image-2.jpg
      md5: d48bcde1db01d8b52cf9a13bfac8b799
      size: 64501
    - path: metrics/segmentation.json
      md5: d168877a43dee0ebb3991df79d951171
      size: 216
    - path: metrics/segmentation/scalars/
      md5: d1072d7a2400a9da186a9353ee4f8e0f.dir
      size: 22600
      nfiles: 4
    - path: models/segmentation/
      md5: e603288dbbd9abdd9725e917d2b4ff50.dir
      size: 35949358
      nfiles: 5
  eval-end-2-end:
    cmd: python watch_recognition/watch_recognition/eval/end_to_end_eval.py --run-concurrently
      --split=val
    deps:
    - path: datasets/watch-faces-local.json
      md5: b70283f3027b17d5c33f72fe0685e3a5
      size: 1573168
    - path: models/detector
      md5: 1fab3506112358531d4e67f67318d577.dir
      size: 432232708
      nfiles: 5
    - path: models/keypoint
      md5: 50daab5812eecb112f562cdbba8f68f5.dir
      size: 35964730
      nfiles: 6
    - path: models/segmentation
      md5: e603288dbbd9abdd9725e917d2b4ff50.dir
      size: 35949358
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/end_to_end_eval.py
      md5: c48df0afed288ec1b487fc2088b43b86
      size: 8652
    outs:
    - path: metrics/end_2_end_eval.csv
      md5: 29b600c296c925c875dbc86007c3cebd
      size: 5952
    - path: metrics/end_2_end_summary.json
      md5: 0b0acdc3c97b345778bb74d3126280f7
      size: 131
  eval-segmentation:
    cmd: python watch_recognition/watch_recognition/eval/segmentation_eval.py --confidence-threshold
      0.5
    deps:
    - path: models/detector/
      md5: 1fab3506112358531d4e67f67318d577.dir
      size: 432232708
      nfiles: 5
    - path: models/segmentation/
      md5: 226fea3a2fa41377d37c4bab8ddc4ee7.dir
      size: 35949358
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/segmentation_eval.py
      md5: bd04e7ffd7d9d64e4258c38f704171d9
      size: 3342
    outs:
    - path: example_predictions/segmentation/train_0.jpg
      md5: f3aff152abe3ab02e8ff284d31d725a6
      size: 30975
    - path: example_predictions/segmentation/train_1.jpg
      md5: 36d8bdb9b9a8749e4a6d383f834c451f
      size: 27162
    - path: example_predictions/segmentation/train_2.jpg
      md5: 73c5cda741bc082f05d26593fe90d7c0
      size: 57324
    - path: example_predictions/segmentation/train_3.jpg
      md5: 9bf48a5d9bf1137d158485634a6bde26
      size: 50367
    - path: example_predictions/segmentation/train_4.jpg
      md5: 3f85ef6926079d9ec29caaf8bab9b333
      size: 49183
    - path: example_predictions/segmentation/val_0.jpg
      md5: 1a277a086ec2e008e3b6a0d61453145f
      size: 44551
    - path: example_predictions/segmentation/val_1.jpg
      md5: a493d00fcf2e298501fe187b5b62eb63
      size: 56945
    - path: example_predictions/segmentation/val_2.jpg
      md5: a957a1384d98363ea78692e2b96696f2
      size: 42602
    - path: example_predictions/segmentation/val_3.jpg
      md5: edf71523580539ecc6619b01ebd4480d
      size: 52894
    - path: example_predictions/segmentation/val_4.jpg
      md5: bde42d1b3eda94d0d6fbac56e8a5e43b
      size: 48925
