schema: '2.0'
stages:
  download-images:
    cmd: python scripts/download-images.py datasets/watch-faces.json --concurrent
    deps:
    - path: datasets/watch-faces.json
      md5: 32892d7a7c5102db60938951ff189903
      size: 2320904
    - path: scripts/download-images.py
      md5: a037cfab1a482a356f1d7d62804041d3
      size: 3961
    outs:
    - path: datasets/test
      md5: 83c8f03071d62b59f80f3932de0cd01b.dir
      size: 19171059
      nfiles: 57
    - path: datasets/train
      md5: d86bc21cf0dd43e6ddd1bf694961730a.dir
      size: 231416419
      nfiles: 738
    - path: datasets/val
      md5: a92d0ff545c47ed5c22cd97dc73e5957.dir
      size: 21867102
      nfiles: 43
    - path: datasets/watch-faces-local.json
      md5: 58b0f36a7c610507073ccc2dc3d20290
      size: 2301699
  train-detector:
    cmd: python watch_recognition/watch_recognition/train/object_detection_tf_model_garden.py
      "train-configs/tf-model-garden/watch-face-detector/" --seed 42
    deps:
    - path: datasets/tf-records/object-detection/watch-faces/
      md5: 45c36d0d23bc8b31f6038bcf96bdec66.dir
      size: 259463443
      nfiles: 4
    - path: train-configs/tf-model-garden/watch-face-detector/retinanet_task.yaml
      md5: 4cc3a22904a608cb4a5e0bc19f2bdfad
      size: 3247
    - path: train-configs/tf-model-garden/watch-face-detector/runtime.yaml
      md5: 71503a0285b578c4ccd9b2cbea2f4a74
      size: 405
    - path: train-configs/tf-model-garden/watch-face-detector/trainer.yaml
      md5: d6a17c825eeee10d90ca143bb4604f69
      size: 845
    params:
      params.yaml:
        detector:
          epochs: 100
          batch-size: 1
          confidence-threshold: 0.5
          label_to_cls:
            WatchFace: 1
        seed: 42
    outs:
    - path: debug/detector/
      md5: d70b5004a852f4767a7bf2587f5fbe80.dir
      size: 272870
      nfiles: 1
    - path: models/detector/
      md5: 58518bc50561568de3f98686f5935ec9.dir
      size: 321639160
      nfiles: 5
  eval-detector:
    cmd: python watch_recognition/watch_recognition/eval/object_detection_eval.py
    deps:
    - path: datasets/test
      md5: c3b9fc1ebd7a05cbf2dfe0c54f2fe397.dir
      size: 18869343
      nfiles: 55
    - path: datasets/train
      md5: 564e5c2bd6e82f4d17952f9fc2d0dd8b.dir
      size: 220071018
      nfiles: 692
    - path: datasets/val
      md5: c2e5983ceddfc4ca034e7992c059f2fd.dir
      size: 20206227
      nfiles: 42
    - path: exported_models/detector/serving/
      md5: 65386a7d39f85d1f17cad3295698eb35.dir
      size: 143112069
      nfiles: 8
    outs:
    - path: example_predictions/detector/train_0.jpg
      md5: 72eb85d4b248b013e1780d962d36ef55
      size: 50754
    - path: example_predictions/detector/train_1.jpg
      md5: c9adb048c99f16a451cc270c8b05db64
      size: 44144
    - path: example_predictions/detector/train_2.jpg
      md5: 423b92d7f8ee6ada84c781025ac51784
      size: 43900
    - path: example_predictions/detector/val_0.jpg
      md5: 0e3ea39f90c009e79c0daa1a7dad560e
      size: 40986
    - path: example_predictions/detector/val_1.jpg
      md5: 040d6f52b16539fccd2ba9fd33110de5
      size: 55781
    - path: example_predictions/detector/val_2.jpg
      md5: b55dc9acd736b7b06cb419a2e6f4e466
      size: 30102
    - path: metrics/detector/train/PR-IoU@0.50.tsv
      md5: 15f501a877d062e3be3477aab9af5629
      size: 2423
    - path: metrics/detector/train/PR-IoU@0.75.tsv
      md5: d93af0ad79d3a1a59493240a36f3bd90
      size: 2455
    - path: metrics/detector/train/PR-IoU@0.95.tsv
      md5: e0209a837a72ba9eb6fc24ae8d0512ed
      size: 1399
    - path: metrics/detector/train/coco.json
      md5: 073139f95b83e099106fef742dacf704
      size: 286
    - path: metrics/detector/train/detection.json
      md5: c327e36cd737ce141c1b92b15e9bd244
      size: 135
    - path: metrics/detector/val/PR-IoU@0.50.tsv
      md5: 29a651c0d7c2a10b5f24de57838a612c
      size: 2164
    - path: metrics/detector/val/PR-IoU@0.75.tsv
      md5: 6053e7e25f73c7ce5c3924fa9f1aff05
      size: 1750
    - path: metrics/detector/val/PR-IoU@0.95.tsv
      md5: ec06f56e8221d92b3a41680ab75c418d
      size: 1059
    - path: metrics/detector/val/coco.json
      md5: fdeb918be2d64507433287b4e30b7f8a
      size: 285
    - path: metrics/detector/val/detection.json
      md5: 59b8478f36d6aeeba97fcedf3d44902f
      size: 133
  update-metrics:
    cmd: python scripts/update-metrics-table-and-graph.py
    deps:
    - path: metrics
      md5: 7720dbd530419e0aed0127b256d6495e.dir
      size: 212311
      nfiles: 38
    - path: scripts/update-metrics-table-and-graph.py
      md5: 6a91ab9d3e3ba8ec6a3fa252dd1853cb
      size: 2068
  train-keypoint:
    cmd: python watch_recognition/watch_recognition/train/heatmap_regression_task.py
      --epochs 100 --batch-size 32 --confidence-threshold 0.5 --seed 42
    deps:
    - path: datasets/test
      md5: 0aeb029db40e49068d63308665810b57.dir
      size: 18701099
      nfiles: 54
    - path: datasets/train
      md5: 9c414afa46808b376366ae8e0ff3c786.dir
      size: 170152358
      nfiles: 481
    - path: datasets/val
      md5: 1ab506f4b22a797ed4afeaf195c51466.dir
      size: 19774777
      nfiles: 40
    - path: datasets/watch-faces-local.json
      md5: ddb1e52cb640b1af3e8ba6c7c85c943a
      size: 1744824
    - path: watch_recognition/watch_recognition/train/heatmap_regression_task.py
      md5: f6a86273f89a38a8abdb8575ec154e9d
      size: 8953
    params:
      params.yaml:
        keypoint:
          epochs: 100
          batch-size: 32
          confidence-threshold: 0.5
          label_to_cls:
            Top: 0
            Center: 1
            Crown: 2
          disk_radius: 5
        max_images:
        seed: 42
    outs:
    - path: debug/keypoint/
      md5: 2ac270cd02a60722351bada220d03d8c.dir
      size: 399737
      nfiles: 2
    - path: example_predictions/keypoint/test-image-2.jpg
      md5: 89d44b8cb435b07ac4634e13eaa00860
      size: 66334
    - path: metrics/keypoint/metrics.json
      md5: c479e42ab5fdf1aa00041a9ea746728e
      size: 214
    - path: metrics/keypoint/plots/
      md5: c6572a9c857b01e34dc8b7b1bc49ff3c.dir
      size: 8908
      nfiles: 4
    - path: models/keypoint/
      md5: 4a34792d0d5209c621c38464f1614818.dir
      size: 35988621
      nfiles: 6
  eval-keypoint:
    cmd: python watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      --kp-confidence-threshold 0.5
    deps:
    - path: models/detector/
      md5: 1fab3506112358531d4e67f67318d577.dir
      size: 432232708
      nfiles: 5
    - path: models/keypoint/
      md5: 61e3f9286fc1eb9530e2878629990abc.dir
      size: 35964730
      nfiles: 6
    - path: watch_recognition/watch_recognition/eval/keypoint_detection_eval.py
      md5: 7aee96c16f50bc522e62bc9138f49247
      size: 6302
    outs:
    - path: example_predictions/keypoint/train_0.jpg
      md5: 065902c4224d6e4ded2ffd5eb1c5fb2d
      size: 25458
    - path: example_predictions/keypoint/train_1.jpg
      md5: 87be1633d4e2629e598184dbafd5dc90
      size: 21951
    - path: example_predictions/keypoint/train_2.jpg
      md5: f092b0e3656b1527980d3f5ee4472c4a
      size: 42166
    - path: example_predictions/keypoint/train_3.jpg
      md5: b0e9da65d6eb0f0d881d395ab00daae6
      size: 38041
    - path: example_predictions/keypoint/train_4.jpg
      md5: 6ec1e284d155bb0795063726e8ef81af
      size: 37605
    - path: example_predictions/keypoint/val_0.jpg
      md5: f4233d485b75ab4fa2c6ddf7b09af9d7
      size: 53245
    - path: example_predictions/keypoint/val_1.jpg
      md5: f3872f5c07a702cfd6667dc2d399fc21
      size: 60953
    - path: example_predictions/keypoint/val_2.jpg
      md5: e688033fb3d853f1812251060dca598b
      size: 48369
    - path: example_predictions/keypoint/val_3.jpg
      md5: 571341fd9f985c0e7be89ea985e9fe93
      size: 57673
    - path: example_predictions/keypoint/val_4.jpg
      md5: 3ede96a954d7b20bb21a9a9f2a4d8621
      size: 51549
    - path: metrics/keypoint/coco_train.json
      md5: 4c4fdf89b72a329b4e0b47985bf12a9e
      size: 260
    - path: metrics/keypoint/coco_val.json
      md5: fad55e8d91734f2d590a026e55746447
      size: 248
  train-segmentation:
    cmd: python watch_recognition/watch_recognition/train/segmentation_tf_model_garden.py
      --seed 42
    deps:
    - path: checkpoints/segmentation/deeplabv3_mobilenetv2_coco
      md5: a37c21ee286ab71978e317df682db5f2.dir
      size: 29628857
      nfiles: 2
    - path: datasets/tf-records/segmentation/watch-hands/watch-hands-train-00001-of-00001.tfrecord
      md5: 6556ca39c3e1e53068bfea67af91310d
      size: 27688326
    - path: datasets/tf-records/segmentation/watch-hands/watch-hands-val-00001-of-00001.tfrecord
      md5: 0ccbf420ddf4f754be1305eba9adf764
      size: 2730084
    - path: train-configs/tf-model-garden/watch-hands-segmentation
      md5: c7fd488223a578e54483ebe0fc18819d.dir
      size: 9313
      nfiles: 5
    params:
      params.yaml:
        seed: 42
        segmentation:
          epochs: 150
          batch-size: 32
          confidence-threshold: 0.5
          label_to_cls:
            Hands: 1
          bbox_labels:
          - WatchFace
    outs:
    - path: debug/segmentation/train_data_0.png
      md5: 2bca295de45ca9d1e17fd9acbaa1ba1b
      size: 713705
    - path: debug/segmentation/train_data_1.png
      md5: f696ccd130951db9978f6b2c4b0856d9
      size: 748308
    - path: debug/segmentation/train_data_2.png
      md5: 1c246ebb9c1d56d48d666fee4b294361
      size: 766920
    - path: debug/segmentation/train_data_predict_0.png
      md5: d8836051608ccc1acb0da257769e8a06
      size: 252657
    - path: models/segmentation/
      md5: 8ff1725b35de069e2459d1a5090e3632.dir
      size: 85962077
      nfiles: 5
  eval-end-2-end:
    cmd: python watch_recognition/watch_recognition/eval/end_to_end_eval.py --run-concurrently
      --split=val
    deps:
    - path: datasets/watch-faces-local.json
      md5: b70283f3027b17d5c33f72fe0685e3a5
      size: 1573168
    - path: models/detector
      md5: 1fab3506112358531d4e67f67318d577.dir
      size: 432232708
      nfiles: 5
    - path: models/keypoint
      md5: 61e3f9286fc1eb9530e2878629990abc.dir
      size: 35964730
      nfiles: 6
    - path: models/segmentation
      md5: e603288dbbd9abdd9725e917d2b4ff50.dir
      size: 35949358
      nfiles: 5
    - path: watch_recognition/watch_recognition/eval/end_to_end_eval.py
      md5: c48df0afed288ec1b487fc2088b43b86
      size: 8652
    outs:
    - path: metrics/end_2_end_eval.csv
      md5: 760a2cbeead50d05ac8874d97761747a
      size: 5955
    - path: metrics/end_2_end_summary.json
      md5: efa5cc3780b031a247ae9dc26e7daa39
      size: 132
  eval-segmentation:
    cmd: python watch_recognition/watch_recognition/eval/segmentation_eval.py --confidence-threshold
      0.5 --save-per-image-metrics
    deps:
    - path: exported_models/segmentation/hands
      md5: 3b58dc1f0c04c81221946dbc722111ae.dir
      size: 78526747
      nfiles: 11
    - path: watch_recognition/watch_recognition/eval/segmentation_eval.py
      md5: 69c563b086ab56ae5130bfedde60694d
      size: 6988
    outs:
    - path: example_predictions/segmentation/hands/train_0.jpg
      md5: 981b2797663edf82dc18d038b0baa060
      size: 23901
    - path: example_predictions/segmentation/hands/train_1.jpg
      md5: 2f1a00479c4bb11f8f1307b464311af8
      size: 19262
    - path: example_predictions/segmentation/hands/train_2.jpg
      md5: 07b002a4502425405f6d7b2c315a056d
      size: 27776
    - path: example_predictions/segmentation/hands/train_3.jpg
      md5: 422ba7e750c8aa26bf0b644603fd14ae
      size: 19985
    - path: example_predictions/segmentation/hands/train_4.jpg
      md5: 1eb87c3a78b8f1d9fd5534f6889473fc
      size: 20760
    - path: example_predictions/segmentation/hands/val_0.jpg
      md5: 1ab371cd4286f11131d9f678a7be7b04
      size: 22880
    - path: example_predictions/segmentation/hands/val_1.jpg
      md5: 91c5db22d16737131620ade14e5d7d8d
      size: 29674
    - path: example_predictions/segmentation/hands/val_2.jpg
      md5: 4d9fdeb6b58b53d2298beb3f258061f8
      size: 21951
    - path: example_predictions/segmentation/hands/val_3.jpg
      md5: a53fea6e3d692c87f7e2082bd224ac0a
      size: 28462
    - path: example_predictions/segmentation/hands/val_4.jpg
      md5: abaec18c8c9b3d8efa919727cdd257c7
      size: 20012
    - path: metrics/segmentation/hands/train/segmentation.json
      md5: fa129b59bebe01ac48ec04f9e1f275fd
      size: 699
    - path: metrics/segmentation/hands/train/segmentation_eval_per_image.csv
      md5: 4dc012dd133efb717dfdd704a68e7329
      size: 12632
    - path: metrics/segmentation/hands/val/segmentation.json
      md5: 38ba61d92b4511880a9de75f3d94dfda
      size: 694
    - path: metrics/segmentation/hands/val/segmentation_eval_per_image.csv
      md5: 54402e2c0627d9086bab3138575d07da
      size: 2939
  generate-detection-dataset:
    cmd: python watch_recognition/watch_recognition/datasets/generate_detection_tf_records.py  datasets/watch-faces-local.json  datasets/tf-records/object-detection/watch-faces/  --num-shards=1
      --run-concurrently
    deps:
    - path: datasets/test
      md5: c3b9fc1ebd7a05cbf2dfe0c54f2fe397.dir
      size: 18869343
      nfiles: 55
    - path: datasets/train
      md5: 564e5c2bd6e82f4d17952f9fc2d0dd8b.dir
      size: 220071018
      nfiles: 692
    - path: datasets/val
      md5: c2e5983ceddfc4ca034e7992c059f2fd.dir
      size: 20206227
      nfiles: 42
    - path: datasets/watch-faces-local.json
      md5: 5967d4bbad75ce2f0becf98f53c2029c
      size: 1877638
    params:
      params.yaml:
        detector.label_to_cls:
          WatchFace: 1
    outs:
    - path: datasets/tf-records/object-detection/watch-faces/watch-faces-test-00001-of-00001.tfrecord
      md5: a555b808d9d7f608d3204f5aa90b02eb
      size: 18894906
    - path: datasets/tf-records/object-detection/watch-faces/watch-faces-train-00001-of-00001.tfrecord
      md5: ebdb72874bb6c7f193fc589f736bc8e3
      size: 220347192
    - path: datasets/tf-records/object-detection/watch-faces/watch-faces-val-00001-of-00001.tfrecord
      md5: 61b08868ea0f804e6fd9dcaaee60055a
      size: 20220589
  generate-watch-hands-dataset:
    cmd: python watch_recognition/watch_recognition/datasets/generate_segmentation_tf_records.py
      datasets/watch-faces-local.json  datasets/tf-records/segmentation/watch-hands/  --num-shards=1
      --run-concurrently
    deps:
    - path: datasets/test
      md5: c3b9fc1ebd7a05cbf2dfe0c54f2fe397.dir
      size: 18869343
      nfiles: 55
    - path: datasets/val
      md5: c2e5983ceddfc4ca034e7992c059f2fd.dir
      size: 20206227
      nfiles: 42
    - path: datasets/watch-faces-local.json
      md5: 3255f41be92d5d2e70a0bf91c953bb5e
      size: 1929022
    params:
      params.yaml:
        segmentation.bbox_labels:
        - WatchFace
        segmentation.label_to_cls:
          Hands: 1
    outs:
    - path: datasets/tf-records/segmentation/watch-hands/watch-hands-train-00001-of-00001.tfrecord
      md5: 6556ca39c3e1e53068bfea67af91310d
      size: 27688326
    - path: datasets/tf-records/segmentation/watch-hands/watch-hands-val-00001-of-00001.tfrecord
      md5: 0ccbf420ddf4f754be1305eba9adf764
      size: 2730084
  export-detector:
    cmd: python watch_recognition/watch_recognition/export/export_retinanet.py models/detector/
    deps:
    - path: datasets/tf-records/object-detection/watch-faces/watch-faces-train-00001-of-00001.tfrecord
      md5: ebdb72874bb6c7f193fc589f736bc8e3
      size: 220347192
    - path: models/detector/
      md5: 58518bc50561568de3f98686f5935ec9.dir
      size: 321639160
      nfiles: 5
    - path: train-configs/tf-model-garden/watch-face-detector/retinanet_task.yaml
      md5: 4cc3a22904a608cb4a5e0bc19f2bdfad
      size: 3247
    - path: train-configs/tf-model-garden/watch-face-detector/runtime.yaml
      md5: 71503a0285b578c4ccd9b2cbea2f4a74
      size: 405
    - path: train-configs/tf-model-garden/watch-face-detector/trainer.yaml
      md5: d6a17c825eeee10d90ca143bb4604f69
      size: 845
    outs:
    - path: example_predictions/detector/IMG_0040.jpg
      md5: 5abcc4ff8c0980a4e3f549c0350164f3
      size: 229262
    - path: exported_models/detector/lite16/assets.extra/tf_serving_warmup_requests
      md5: 8c7059090db70976a01dfc2e8dd1c968
      size: 1769557
    - path: exported_models/detector/lite16/model.tflite
      md5: 6e4ece3f68f8dbdc8539701d2157f0ad
      size: 54973072
    - path: exported_models/detector/lite8/assets.extra/tf_serving_warmup_requests
      md5: 8c7059090db70976a01dfc2e8dd1c968
      size: 1769557
    - path: exported_models/detector/lite8/model.tflite
      md5: 1c42bf583af00e08292d6eeca93530e4
      size: 91696144
    - path: exported_models/detector/serving/assets.extra/tf_serving_warmup_requests
      md5: 783b65cb6c06d334aaf972183d2c4409
      size: 11520090
    - path: exported_models/detector/serving/fingerprint.pb
      md5: 96646ded012898254be320f2d8b65943
      size: 55
    - path: exported_models/detector/serving/saved_model.pb
      md5: bec4b4e548ae57f5a2230e93c11a4953
      size: 23869403
    - path: exported_models/detector/serving/variables/variables.data-00000-of-00001
      md5: 47de8ee9f3fdf79eb71ad04f26c6d272
      size: 107671904
    - path: exported_models/detector/serving/variables/variables.index
      md5: c44f4054fe1df9b9eb6374d50816c1e0
      size: 50501
  render-demo:
    cmd: scripts/render-demo-movie.py example_data/IMG_1200_720p.mov demo/demo.mp4
      --enable-multithreading
    deps:
    - path: example_data/IMG_1200_720p.mov
      md5: 5dfad65d6cb1231b1dc70d24153ef52a
      size: 12545634
    - path: exported_models/detector
      md5: 7fc9b7e863d197568080c354352f4985.dir
      size: 293320455
      nfiles: 14
    - path: exported_models/segmentation/hands
      md5: 75cdc6bcd06e0e161e91c4e0a2169986.dir
      size: 4385089974
      nfiles: 11
    - path: models/keypoint
      md5: 4a34792d0d5209c621c38464f1614818.dir
      size: 35988621
      nfiles: 6
    - path: scripts/render-demo-movie.py
      md5: 593f9b82a46a183471f4e061473520f5
      size: 4455
    outs:
    - path: demo/demo.mp4
      md5: 640daf05552d320f0ef1809d376962fa
      size: 8978442
  export-segmentation:
    cmd: python watch_recognition/watch_recognition/export/export_segmentation.py
      models/segmentation train-configs/tf-model-garden/watch-hands-segmentation/
    deps:
    - path: models/segmentation/
      md5: 8ff1725b35de069e2459d1a5090e3632.dir
      size: 85962077
      nfiles: 5
    - path: train-configs/tf-model-garden/watch-hands-segmentation
      md5: d7d840cb70aa393c5fe143010e06d427.dir
      size: 4859
      nfiles: 3
    outs:
    - path: example_predictions/segmentation/hands/example-1.jpg
      md5: fabd62e6182cf7e3222ff326082a9cd1
      size: 60087
    - path: exported_models/segmentation/hands/
      md5: 3b58dc1f0c04c81221946dbc722111ae.dir
      size: 78526747
      nfiles: 11
  segmentation-generate-dataset:
    cmd: python watch_recognition/watch_recognition/datasets/generate_segmentation_tf_records.py
      datasets/watch-faces-local.json  datasets/tf-records/segmentation/watch-hands/  --num-shards=1
      --run-concurrently
    deps:
    - path: datasets/test
      md5: 83c8f03071d62b59f80f3932de0cd01b.dir
      size: 19171059
      nfiles: 57
    - path: datasets/val
      md5: a92d0ff545c47ed5c22cd97dc73e5957.dir
      size: 21867102
      nfiles: 43
    - path: datasets/watch-faces-local.json
      md5: 58b0f36a7c610507073ccc2dc3d20290
      size: 2301699
    params:
      params.yaml:
        segmentation.bbox_labels:
        - WatchFace
        segmentation.label_to_cls:
          Hands: 1
    outs:
    - path: datasets/tf-records/segmentation/watch-hands/watch-hands-train-00001-of-00001.tfrecord
      md5: f22ace72dab4a6bbc0c0ce5d79610582
      size: 28553595
    - path: datasets/tf-records/segmentation/watch-hands/watch-hands-val-00001-of-00001.tfrecord
      md5: cdb0ac719732f4ba771e948fc3845ae3
      size: 3007009
  segmentation-train:
    cmd: python watch_recognition/watch_recognition/train/segmentation_tf_model_garden.py
      --seed 42
    deps:
    - path: checkpoints/segmentation/deeplabv3_mobilenetv2_coco
      md5: a37c21ee286ab71978e317df682db5f2.dir
      size: 29628857
      nfiles: 2
    - path: datasets/tf-records/segmentation/watch-hands/watch-hands-train-00001-of-00001.tfrecord
      md5: f22ace72dab4a6bbc0c0ce5d79610582
      size: 28553595
    - path: datasets/tf-records/segmentation/watch-hands/watch-hands-val-00001-of-00001.tfrecord
      md5: cdb0ac719732f4ba771e948fc3845ae3
      size: 3007009
    - path: train-configs/tf-model-garden/watch-hands-segmentation
      md5: b8de89278388faf78ecb40db91ad8e7e.dir
      size: 4995
      nfiles: 3
    params:
      params.yaml:
        seed: 42
        segmentation:
          epochs: 150
          batch-size: 32
          confidence-threshold: 0.5
          label_to_cls:
            Hands: 1
          bbox_labels:
          - WatchFace
    outs:
    - path: debug/segmentation/train_data_0.png
      md5: badfad1fcf3b17efc25a809be44f8a73
      size: 752966
    - path: debug/segmentation/train_data_1.png
      md5: c1dc4b20cc2c30af04cf2dead586ff0b
      size: 827853
    - path: debug/segmentation/train_data_2.png
      md5: 28bfae89c915d1e70d89dd5b50d3cd2f
      size: 806549
    - path: debug/segmentation/train_data_predict_0.png
      md5: d8672798705d35c902cb52da2a92792d
      size: 246022
    - path: models/segmentation/
      md5: ed11e4dbe25ada08faa68fe49a603c54.dir
      size: 6559431200
      nfiles: 5
  segmentation-export:
    cmd: python watch_recognition/watch_recognition/export/export_segmentation.py
      models/segmentation train-configs/tf-model-garden/watch-hands-segmentation/
    deps:
    - path: models/segmentation/
      md5: ed11e4dbe25ada08faa68fe49a603c54.dir
      size: 6559431200
      nfiles: 5
    - path: train-configs/tf-model-garden/watch-hands-segmentation
      md5: b8de89278388faf78ecb40db91ad8e7e.dir
      size: 4995
      nfiles: 3
    outs:
    - path: example_predictions/segmentation/hands/example-1.jpg
      md5: 17f7aeb20c93c3f2776207ea8f441907
      size: 60098
    - path: exported_models/segmentation/hands/
      md5: 75cdc6bcd06e0e161e91c4e0a2169986.dir
      size: 4385089974
      nfiles: 11
  segmentation-eval:
    cmd: python watch_recognition/watch_recognition/eval/segmentation_eval.py --confidence-threshold
      0.5 --save-per-image-metrics
    deps:
    - path: exported_models/segmentation/hands
      md5: a4f23bd760779ae14a3ef853ef9808f7.dir
      size: 4385086547
      nfiles: 11
    - path: watch_recognition/watch_recognition/eval/segmentation_eval.py
      md5: 69c563b086ab56ae5130bfedde60694d
      size: 6988
    outs:
    - path: example_predictions/segmentation/hands/train_0.jpg
      md5: 3af54cc0dad9fb59d5b66de31a43161e
      size: 23945
    - path: example_predictions/segmentation/hands/train_1.jpg
      md5: 5dd9095e3ca23cdefb4c30dcef2bd455
      size: 19276
    - path: example_predictions/segmentation/hands/train_2.jpg
      md5: 0ba3e35d7bf7fbe193ec2aef0b44118f
      size: 27758
    - path: example_predictions/segmentation/hands/train_3.jpg
      md5: 4ac60ab532061b343105b9fb982955c5
      size: 20029
    - path: example_predictions/segmentation/hands/train_4.jpg
      md5: 086fef00626f93ec71b564dc7be15721
      size: 20775
    - path: example_predictions/segmentation/hands/val_0.jpg
      md5: f9e58d6974562f2db2fd7c63abfc9e1e
      size: 22862
    - path: example_predictions/segmentation/hands/val_1.jpg
      md5: 21e0f76d1cfe53880129a3c9c31be495
      size: 29690
    - path: example_predictions/segmentation/hands/val_2.jpg
      md5: f8a1b693cc79a517a7354029d7a3ecc4
      size: 21941
    - path: example_predictions/segmentation/hands/val_3.jpg
      md5: be158a56bf001b77723d46197b1a2ecf
      size: 28476
    - path: example_predictions/segmentation/hands/val_4.jpg
      md5: 925d47d131e86ee6505dbde3ce49b49b
      size: 20024
    - path: metrics/segmentation/hands/train/segmentation.json
      md5: a57cc8d1d4cfaa3895583b568f8ba6ed
      size: 698
    - path: metrics/segmentation/hands/train/segmentation_eval_per_image.csv
      md5: 90dd676498cff69206708e30a8aacf77
      size: 12983
    - path: metrics/segmentation/hands/val/segmentation.json
      md5: 5a0ad1ca0c3928ffde47c9b2e9920ddd
      size: 694
    - path: metrics/segmentation/hands/val/segmentation_eval_per_image.csv
      md5: 9443977f110e5bb83102a2419aa1e213
      size: 2946
  detection-generate-dataset:
    cmd: python watch_recognition/watch_recognition/datasets/generate_detection_tf_records.py  datasets/watch-faces-local.json  datasets/tf-records/object-detection/watch-faces/  --num-shards=1
      --run-concurrently
    deps:
    - path: datasets/test
      md5: 83c8f03071d62b59f80f3932de0cd01b.dir
      size: 19171059
      nfiles: 57
    - path: datasets/train
      md5: d86bc21cf0dd43e6ddd1bf694961730a.dir
      size: 231416419
      nfiles: 738
    - path: datasets/val
      md5: a92d0ff545c47ed5c22cd97dc73e5957.dir
      size: 21867102
      nfiles: 43
    - path: datasets/watch-faces-local.json
      md5: 58b0f36a7c610507073ccc2dc3d20290
      size: 2301699
    params:
      params.yaml:
        detector.label_to_cls:
          WatchFace: 1
    outs:
    - path: datasets/tf-records/object-detection/watch-faces/watch-faces-test-00001-of-00001.tfrecord
      md5: e906c57568a6a9663ed161da3a4a07db
      size: 19197638
    - path: datasets/tf-records/object-detection/watch-faces/watch-faces-train-00001-of-00001.tfrecord
      md5: 50172c7a83f3656110e6f077babfd812
      size: 231714428
    - path: datasets/tf-records/object-detection/watch-faces/watch-faces-val-00001-of-00001.tfrecord
      md5: 7468baea57796d30310d3f7eb061baf6
      size: 21883157
  detection-train:
    cmd: python watch_recognition/watch_recognition/train/object_detection_tf_model_garden.py
      "train-configs/tf-model-garden/watch-face-detector/" --seed 42
    deps:
    - path: datasets/tf-records/object-detection/watch-faces/
      md5: 68a1e50b280f617796369b368c9fff56.dir
      size: 272795979
      nfiles: 4
    - path: train-configs/tf-model-garden/watch-face-detector/retinanet_task.yaml
      md5: 4cc3a22904a608cb4a5e0bc19f2bdfad
      size: 3247
    - path: train-configs/tf-model-garden/watch-face-detector/runtime.yaml
      md5: 71503a0285b578c4ccd9b2cbea2f4a74
      size: 405
    - path: train-configs/tf-model-garden/watch-face-detector/trainer.yaml
      md5: d6a17c825eeee10d90ca143bb4604f69
      size: 845
    params:
      params.yaml:
        detector:
          epochs: 100
          batch-size: 1
          confidence-threshold: 0.5
          label_to_cls:
            WatchFace: 1
        seed: 42
    outs:
    - path: debug/detector/
      md5: 673c37de9e18b881ab41b86b8a6b4a73.dir
      size: 146107
      nfiles: 1
    - path: models/detector/
      md5: e049636e3b8756ab9edf15bc9434f814.dir
      size: 321639161
      nfiles: 5
  detection-export:
    cmd: python watch_recognition/watch_recognition/export/export_retinanet.py models/detector/
    deps:
    - path: datasets/tf-records/object-detection/watch-faces/watch-faces-train-00001-of-00001.tfrecord
      md5: 50172c7a83f3656110e6f077babfd812
      size: 231714428
    - path: models/detector/
      md5: e049636e3b8756ab9edf15bc9434f814.dir
      size: 321639161
      nfiles: 5
    - path: train-configs/tf-model-garden/watch-face-detector/retinanet_task.yaml
      md5: 4cc3a22904a608cb4a5e0bc19f2bdfad
      size: 3247
    - path: train-configs/tf-model-garden/watch-face-detector/runtime.yaml
      md5: 71503a0285b578c4ccd9b2cbea2f4a74
      size: 405
    - path: train-configs/tf-model-garden/watch-face-detector/trainer.yaml
      md5: d6a17c825eeee10d90ca143bb4604f69
      size: 845
    outs:
    - path: example_predictions/detector/IMG_0040.jpg
      md5: 0d9f8d67eed95c3264a87502d8b19f8e
      size: 95866
    - path: exported_models/detector/lite16/assets.extra/tf_serving_warmup_requests
      md5: 8c7059090db70976a01dfc2e8dd1c968
      size: 1769557
    - path: exported_models/detector/lite16/model.tflite
      md5: 2544844213b291017cf598760e528036
      size: 54973072
    - path: exported_models/detector/lite8/assets.extra/tf_serving_warmup_requests
      md5: 8c7059090db70976a01dfc2e8dd1c968
      size: 1769557
    - path: exported_models/detector/lite8/model.tflite
      md5: 377121906f65d376ce3963e64e186bd4
      size: 91696144
    - path: exported_models/detector/serving/assets.extra/tf_serving_warmup_requests
      md5: 783b65cb6c06d334aaf972183d2c4409
      size: 11520090
    - path: exported_models/detector/serving/fingerprint.pb
      md5: 41d571b3fb5dd07fcf402ad335590d75
      size: 55
    - path: exported_models/detector/serving/saved_model.pb
      md5: 2f9213275429c2749c2fa78107328df9
      size: 23869403
    - path: exported_models/detector/serving/variables/variables.data-00000-of-00001
      md5: adc1a58b12e7d9a93b2f77337518c39d
      size: 107671904
    - path: exported_models/detector/serving/variables/variables.index
      md5: 04571198a69a0ce78757e3d41f986328
      size: 50501
  detection-eval:
    cmd: python watch_recognition/watch_recognition/eval/object_detection_eval.py
    deps:
    - path: datasets/test
      md5: 83c8f03071d62b59f80f3932de0cd01b.dir
      size: 19171059
      nfiles: 57
    - path: datasets/train
      md5: d86bc21cf0dd43e6ddd1bf694961730a.dir
      size: 231416419
      nfiles: 738
    - path: datasets/val
      md5: a92d0ff545c47ed5c22cd97dc73e5957.dir
      size: 21867102
      nfiles: 43
    - path: exported_models/detector/serving/
      md5: d1cace8c8ed53b94574319128cf30e81.dir
      size: 143112069
      nfiles: 8
    outs:
    - path: example_predictions/detector/train_0.jpg
      md5: 69f9e57f2b4a7c2cd11dd4ee57461a8e
      size: 36402
    - path: example_predictions/detector/train_1.jpg
      md5: 7460089acf4348613f63be023ed7d332
      size: 23419
    - path: example_predictions/detector/train_2.jpg
      md5: 0fc35b3df48f0397683e284cb2962985
      size: 24223
    - path: example_predictions/detector/val_0.jpg
      md5: aea48accbcfd0d53939fb61d4fcb4ce7
      size: 17557
    - path: example_predictions/detector/val_1.jpg
      md5: 99964f7a2a4e0617eee0273c58ba186d
      size: 23501
    - path: example_predictions/detector/val_2.jpg
      md5: c1ab5162dd45b62d09f83a26411b3ee4
      size: 14633
    - path: metrics/detector/train/PR-IoU@0.50.tsv
      md5: be633215eef36b9ff6514e8a6eb85eab
      size: 2401
    - path: metrics/detector/train/PR-IoU@0.75.tsv
      md5: 43a7e0fc1655f53c4a24b93ab758d611
      size: 2387
    - path: metrics/detector/train/PR-IoU@0.95.tsv
      md5: 8e8d535ed80433d85c0a9e9869a9e309
      size: 1373
    - path: metrics/detector/train/coco.json
      md5: 14de9fe621396d3db19fbef63723c35b
      size: 286
    - path: metrics/detector/train/detection.json
      md5: 99fc69fff66fa5866b6af83914e914b1
      size: 135
    - path: metrics/detector/val/PR-IoU@0.50.tsv
      md5: a94e38bcc918294ed893aa8ed7a49d25
      size: 1830
    - path: metrics/detector/val/PR-IoU@0.75.tsv
      md5: cd6007615b730e2e134a88ca9c5b04a1
      size: 1480
    - path: metrics/detector/val/PR-IoU@0.95.tsv
      md5: 765da750316116833188323b2d88731a
      size: 1119
    - path: metrics/detector/val/coco.json
      md5: 23802039607978f633d762b9ee369676
      size: 286
    - path: metrics/detector/val/detection.json
      md5: a742ede3aa83c7a5d89b24fb896a861c
      size: 121
